{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb0292f2",
   "metadata": {},
   "source": [
    "<h1>ASL Alphabet Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1e8c0",
   "metadata": {},
   "source": [
    "<h2>1. Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df54f295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data for class Y\n",
      "Starting from counter value: 200 (found 200 existing images)\n",
      "Collected 100 new images for class Y. Total: 300\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "DATA_DIR = './data_alphabet'\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "# classes = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y']\n",
    "#            ,'0','1','2','3','4','5','6','7','8','9']\n",
    "# classes = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N']\n",
    "classes = ['Y']\n",
    "dataset_size = 100\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "for j in classes:\n",
    "    if not os.path.exists(os.path.join(DATA_DIR, j)):\n",
    "        os.makedirs(os.path.join(DATA_DIR, j))\n",
    "\n",
    "    print(f'Collecting data for class {j}')\n",
    "    \n",
    "    # Find the highest number in existing filenames to continue from there\n",
    "    existing_files = os.listdir(os.path.join(DATA_DIR, j))\n",
    "    existing_numbers = []\n",
    "    for filename in existing_files:\n",
    "        try:\n",
    "            # Extract the number from filenames like \"123.jpg\"\n",
    "            num = int(os.path.splitext(filename)[0])\n",
    "            existing_numbers.append(num)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    # If there are existing files, start counting after the highest number\n",
    "    # Otherwise start from 0\n",
    "    starting_counter = max(existing_numbers) + 1 if existing_numbers else 0\n",
    "    print(f\"Starting from counter value: {starting_counter} (found {len(existing_numbers)} existing images)\")\n",
    "\n",
    "    done = False\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.putText(frame, 'Ready? Press \"Q\" ! :)', (100, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3,\n",
    "                    cv2.LINE_AA)\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(25) == ord('q'):\n",
    "            break\n",
    "\n",
    "    counter = starting_counter\n",
    "    target_count = starting_counter + dataset_size\n",
    "    \n",
    "    while counter < target_count:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.putText(frame, f'Collecting: {counter-starting_counter+1}/{dataset_size}', (50, 50), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.waitKey(25)\n",
    "        cv2.imwrite(os.path.join(DATA_DIR, str(j), '{}.jpg'.format(counter)), frame)\n",
    "\n",
    "        counter += 1\n",
    "    \n",
    "    print(f\"Collected {dataset_size} new images for class {j}. Total: {target_count}\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1732627",
   "metadata": {},
   "source": [
    "<h3>2. Create Dataset for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d244665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping directory: .DS_Store\n",
      "Processing class: R\n",
      "Class R: Processed 300/300 images successfully\n",
      "Processing class: U\n",
      "Class U: Processed 270/300 images successfully\n",
      "Processing class: I\n",
      "Class I: Processed 300/300 images successfully\n",
      "Processing class: N\n",
      "Class N: Processed 300/300 images successfully\n",
      "Processing class: G\n",
      "Class G: Processed 300/300 images successfully\n",
      "Processing class: T\n",
      "Class T: Processed 300/300 images successfully\n",
      "Processing class: S\n",
      "Class S: Processed 300/300 images successfully\n",
      "Processing class: A\n",
      "Class A: Processed 300/300 images successfully\n",
      "Processing class: F\n",
      "Class F: Processed 300/300 images successfully\n",
      "Processing class: O\n",
      "Class O: Processed 300/300 images successfully\n",
      "Processing class: H\n",
      "Class H: Processed 296/300 images successfully\n",
      "Processing class: M\n",
      "Class M: Processed 299/300 images successfully\n",
      "Processing class: J\n",
      "Class J: Processed 300/300 images successfully\n",
      "Processing class: C\n",
      "Class C: Processed 296/300 images successfully\n",
      "Processing class: D\n",
      "Class D: Processed 300/300 images successfully\n",
      "Processing class: V\n",
      "Class V: Processed 291/300 images successfully\n",
      "Processing class: Q\n",
      "Class Q: Processed 299/300 images successfully\n",
      "Processing class: X\n",
      "Class X: Processed 299/300 images successfully\n",
      "Processing class: E\n",
      "Class E: Processed 300/300 images successfully\n",
      "Processing class: B\n",
      "Class B: Processed 300/300 images successfully\n",
      "Processing class: K\n",
      "Class K: Processed 293/300 images successfully\n",
      "Processing class: L\n",
      "Class L: Processed 300/300 images successfully\n",
      "Processing class: Y\n",
      "Class Y: Processed 300/300 images successfully\n",
      "Processing class: P\n",
      "Class P: Processed 299/300 images successfully\n",
      "Processing class: W\n",
      "Class W: Processed 300/300 images successfully\n",
      "Total: Processed 7442/7500 images successfully\n",
      "Hand detection failures: 58\n",
      "Class distribution: {'A': 300, 'B': 300, 'C': 296, 'D': 300, 'E': 300, 'F': 300, 'G': 300, 'H': 296, 'I': 300, 'J': 300, 'K': 293, 'L': 300, 'M': 299, 'N': 300, 'O': 300, 'P': 299, 'Q': 299, 'R': 300, 'S': 300, 'T': 300, 'U': 270, 'V': 291, 'W': 300, 'X': 299, 'Y': 300}\n",
      "Shuffled dataset saved to data.pickle\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "\n",
    "datas = []\n",
    "labels = []\n",
    "\n",
    "# Only process these directories\n",
    "detection_failures = 0\n",
    "total_images = 0\n",
    "DATA_DIR = './data_alphabet'\n",
    "classes = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y']\n",
    "for dir_ in os.listdir(DATA_DIR):\n",
    "    # Skip hidden files and non-class directories\n",
    "    if dir_.startswith('.') or dir_ not in classes:\n",
    "        print(f\"Skipping directory: {dir_}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing class: {dir_}\")\n",
    "    class_path = os.path.join(DATA_DIR, dir_)\n",
    "\n",
    "    # Skip if not a directory\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    # Process images in this class directory\n",
    "    class_images = 0\n",
    "    class_successes = 0\n",
    "\n",
    "    for img_path in os.listdir(class_path):\n",
    "        if not (img_path.endswith('.jpg') or img_path.endswith('.png')):\n",
    "            continue\n",
    "\n",
    "        total_images += 1\n",
    "        class_images += 1\n",
    "\n",
    "        try:\n",
    "            # Read and process image\n",
    "            img = cv2.imread(os.path.join(class_path, img_path))\n",
    "            if img is None:\n",
    "                print(f\"Failed to read image: {img_path}\")\n",
    "                continue\n",
    "\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Process with MediaPipe\n",
    "            results = hands.process(img_rgb)\n",
    "\n",
    "            if not results.multi_hand_landmarks:\n",
    "                detection_failures += 1\n",
    "                continue\n",
    "\n",
    "            # Get the first detected hand\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "\n",
    "            # Extract and normalize coordinates\n",
    "            x_coords = [landmark.x for landmark in hand_landmarks.landmark]\n",
    "            y_coords = [landmark.y for landmark in hand_landmarks.landmark]\n",
    "\n",
    "            # Normalize relative to hand bounding box\n",
    "            x_min, x_max = min(x_coords), max(x_coords)\n",
    "            y_min, y_max = min(y_coords), max(y_coords)\n",
    "\n",
    "            # Create feature vector\n",
    "            data_aux = []\n",
    "            for i in range(len(hand_landmarks.landmark)):\n",
    "                # Normalize to [0,1] range within hand bounding box\n",
    "                norm_x = (hand_landmarks.landmark[i].x - x_min) / (x_max - x_min) if x_max > x_min else 0\n",
    "                norm_y = (hand_landmarks.landmark[i].y - y_min) / (y_max - y_min) if y_max > y_min else 0\n",
    "\n",
    "                data_aux.append(norm_x)\n",
    "                data_aux.append(norm_y)\n",
    "\n",
    "            # Verify we have the expected number of features\n",
    "            if len(data_aux) != 42:  # 21 landmarks Ã— 2 coordinates\n",
    "                print(f\"Unexpected feature count in {img_path}: {len(data_aux)}\")\n",
    "                continue\n",
    "\n",
    "            datas.append(data_aux)\n",
    "            labels.append(dir_)\n",
    "            class_successes += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "    print(f\"Class {dir_}: Processed {class_successes}/{class_images} images successfully\")\n",
    "\n",
    "print(f\"Total: Processed {len(datas)}/{total_images} images successfully\")\n",
    "print(f\"Hand detection failures: {detection_failures}\")\n",
    "\n",
    "# Check class balance\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "print(\"Class distribution:\", class_distribution)\n",
    "\n",
    "data_array = np.array(datas)\n",
    "label_array = np.array(labels)\n",
    "\n",
    "# Create a random permutation of indices\n",
    "indices = np.random.permutation(len(data_array))\n",
    "\n",
    "# Shuffle both data and labels using the same permutation\n",
    "shuffled_data = data_array[indices]\n",
    "shuffled_labels = label_array[indices]\n",
    "\n",
    "# Save the shuffled dataset\n",
    "f = open('train_data_set/data_alphabet_both.pickle', 'wb')\n",
    "pickle.dump({'data': shuffled_data.tolist(), 'labels': shuffled_labels.tolist()}, f)\n",
    "f.close()\n",
    "print(\"Shuffled dataset saved to data.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd9fc1",
   "metadata": {},
   "source": [
    "<h3>3. Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "032ca89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.backends.mps.is_available()\n",
    "torch.mps.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f0807c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu' # adjust 'mps' for mac or 'gpu' for cuda\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd07e81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min length: 42\n",
      "Max length: 42\n",
      "Unique lengths: {42}\n",
      "Epoch 1/50: Train Loss: 2.5068, Train Acc: 0.2125, Val Loss: 1.1648, Val Acc: 0.5688\n",
      "Epoch 2/50: Train Loss: 1.1638, Train Acc: 0.5522, Val Loss: 0.6575, Val Acc: 0.7703\n",
      "Epoch 3/50: Train Loss: 0.8942, Train Acc: 0.6619, Val Loss: 0.4606, Val Acc: 0.8522\n",
      "Epoch 4/50: Train Loss: 0.7306, Train Acc: 0.7200, Val Loss: 0.4229, Val Acc: 0.8388\n",
      "Epoch 5/50: Train Loss: 0.6261, Train Acc: 0.7638, Val Loss: 0.3171, Val Acc: 0.8899\n",
      "Epoch 6/50: Train Loss: 0.5712, Train Acc: 0.7880, Val Loss: 0.2637, Val Acc: 0.9281\n",
      "Epoch 7/50: Train Loss: 0.4606, Train Acc: 0.8389, Val Loss: 0.2281, Val Acc: 0.9161\n",
      "Epoch 8/50: Train Loss: 0.4568, Train Acc: 0.8350, Val Loss: 0.1805, Val Acc: 0.9584\n",
      "Epoch 9/50: Train Loss: 0.3967, Train Acc: 0.8597, Val Loss: 0.1627, Val Acc: 0.9537\n",
      "Epoch 10/50: Train Loss: 0.3492, Train Acc: 0.8762, Val Loss: 0.1352, Val Acc: 0.9624\n",
      "Epoch 11/50: Train Loss: 0.3324, Train Acc: 0.8824, Val Loss: 0.1184, Val Acc: 0.9718\n",
      "Epoch 12/50: Train Loss: 0.3226, Train Acc: 0.8950, Val Loss: 0.0968, Val Acc: 0.9704\n",
      "Epoch 13/50: Train Loss: 0.2903, Train Acc: 0.9059, Val Loss: 0.0857, Val Acc: 0.9745\n",
      "Epoch 14/50: Train Loss: 0.2685, Train Acc: 0.9125, Val Loss: 0.0807, Val Acc: 0.9839\n",
      "Epoch 15/50: Train Loss: 0.2630, Train Acc: 0.9103, Val Loss: 0.0664, Val Acc: 0.9866\n",
      "Epoch 16/50: Train Loss: 0.2401, Train Acc: 0.9202, Val Loss: 0.0689, Val Acc: 0.9799\n",
      "Epoch 17/50: Train Loss: 0.2219, Train Acc: 0.9227, Val Loss: 0.0572, Val Acc: 0.9872\n",
      "Epoch 18/50: Train Loss: 0.2279, Train Acc: 0.9247, Val Loss: 0.0692, Val Acc: 0.9805\n",
      "Epoch 19/50: Train Loss: 0.2222, Train Acc: 0.9330, Val Loss: 0.0540, Val Acc: 0.9866\n",
      "Epoch 20/50: Train Loss: 0.2136, Train Acc: 0.9279, Val Loss: 0.0528, Val Acc: 0.9913\n",
      "Epoch 21/50: Train Loss: 0.2056, Train Acc: 0.9316, Val Loss: 0.0659, Val Acc: 0.9879\n",
      "Epoch 22/50: Train Loss: 0.1880, Train Acc: 0.9377, Val Loss: 0.0532, Val Acc: 0.9872\n",
      "Epoch 23/50: Train Loss: 0.1751, Train Acc: 0.9446, Val Loss: 0.0419, Val Acc: 0.9926\n",
      "Epoch 24/50: Train Loss: 0.1751, Train Acc: 0.9414, Val Loss: 0.0437, Val Acc: 0.9893\n",
      "Epoch 25/50: Train Loss: 0.1614, Train Acc: 0.9449, Val Loss: 0.0518, Val Acc: 0.9893\n",
      "Epoch 26/50: Train Loss: 0.1567, Train Acc: 0.9474, Val Loss: 0.0392, Val Acc: 0.9913\n",
      "Epoch 27/50: Train Loss: 0.1656, Train Acc: 0.9422, Val Loss: 0.0373, Val Acc: 0.9940\n",
      "Epoch 28/50: Train Loss: 0.1582, Train Acc: 0.9466, Val Loss: 0.0408, Val Acc: 0.9913\n",
      "Epoch 29/50: Train Loss: 0.1427, Train Acc: 0.9523, Val Loss: 0.0348, Val Acc: 0.9940\n",
      "Epoch 30/50: Train Loss: 0.1388, Train Acc: 0.9563, Val Loss: 0.0685, Val Acc: 0.9832\n",
      "Epoch 31/50: Train Loss: 0.1334, Train Acc: 0.9543, Val Loss: 0.0322, Val Acc: 0.9946\n",
      "Epoch 32/50: Train Loss: 0.1379, Train Acc: 0.9543, Val Loss: 0.0475, Val Acc: 0.9919\n",
      "Epoch 33/50: Train Loss: 0.1291, Train Acc: 0.9553, Val Loss: 0.0330, Val Acc: 0.9960\n",
      "Epoch 34/50: Train Loss: 0.1131, Train Acc: 0.9587, Val Loss: 0.0344, Val Acc: 0.9953\n",
      "Epoch 35/50: Train Loss: 0.1186, Train Acc: 0.9609, Val Loss: 0.0488, Val Acc: 0.9913\n",
      "Epoch 36/50: Train Loss: 0.1223, Train Acc: 0.9617, Val Loss: 0.0338, Val Acc: 0.9946\n",
      "Epoch 37/50: Train Loss: 0.1168, Train Acc: 0.9625, Val Loss: 0.0391, Val Acc: 0.9940\n",
      "Epoch 38/50: Train Loss: 0.1123, Train Acc: 0.9647, Val Loss: 0.0362, Val Acc: 0.9933\n",
      "Epoch 39/50: Train Loss: 0.1050, Train Acc: 0.9649, Val Loss: 0.0377, Val Acc: 0.9960\n",
      "Epoch 40/50: Train Loss: 0.1138, Train Acc: 0.9624, Val Loss: 0.0325, Val Acc: 0.9953\n",
      "Epoch 41/50: Train Loss: 0.0991, Train Acc: 0.9662, Val Loss: 0.0311, Val Acc: 0.9960\n",
      "Epoch 42/50: Train Loss: 0.0869, Train Acc: 0.9691, Val Loss: 0.0380, Val Acc: 0.9960\n",
      "Epoch 43/50: Train Loss: 0.0939, Train Acc: 0.9667, Val Loss: 0.0398, Val Acc: 0.9933\n",
      "Early stopping at epoch 43\n",
      "Final test accuracy: 0.9960\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and label mapping saved\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Using GPU to train faster\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "# Load data from pickle file\n",
    "data_dict = pickle.load(open('./train_data_set/data_alphabet_both.pickle', 'rb'))\n",
    "\n",
    "# Extract data and labels\n",
    "data = data_dict['data']\n",
    "labels = np.asarray(data_dict['labels'])\n",
    "\n",
    "# Check for consistency in data lengths\n",
    "lengths = [len(x) for x in data]\n",
    "print(\"Min length:\", min(lengths))\n",
    "print(\"Max length:\", max(lengths))\n",
    "print(\"Unique lengths:\", set(lengths))\n",
    "\n",
    "# Convert data to numpy array with padding if needed\n",
    "if len(set(lengths)) == 1:\n",
    "    # All elements have the same length\n",
    "    data_array = np.array(data, dtype=float)\n",
    "else:\n",
    "    # Elements have different lengths, need padding\n",
    "    max_len = max(lengths)\n",
    "    data_array = np.zeros((len(data), max_len), dtype=float)\n",
    "    for i, item in enumerate(data):\n",
    "        data_array[i, :len(item)] = item\n",
    "\n",
    "# Convert labels to numeric\n",
    "label_map = {label: i for i, label in enumerate(np.unique(labels))}\n",
    "numeric_labels = np.array([label_map[label] for label in labels])\n",
    "reverse_label_map = {i: label for label, i in label_map.items()}\n",
    "\n",
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data_array, numeric_labels, test_size=0.2, shuffle=True, stratify=numeric_labels\n",
    ")\n",
    "\n",
    "# Reshape data for CNN (samples, channels, timesteps, features)\n",
    "# For hand landmarks, we reshape 42 values into 1 channel, 21 timesteps with 2 features (x,y)\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, 21, 2)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, 21, 2)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_train_tensor = torch.FloatTensor(x_train)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "x_test_tensor = torch.FloatTensor(x_test)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define CNN model\n",
    "class HandGestureCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(HandGestureCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 2), padding=(1, 0))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(3, 1), padding=(1, 0))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 1))\n",
    "\n",
    "        # Calculate size after convolutions and pooling\n",
    "        self.fc_input_size = 128 * 5 * 1\n",
    "\n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: \n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(-1, self.fc_input_size)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = HandGestureCNN(num_classes=len(label_map)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training function\n",
    "def train(model, train_loader, criterion, optimizer, device='cpu'):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = correct / total\n",
    "    return train_loss, train_acc\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, test_loader, criterion, device='cpu'):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    test_loss = running_loss / len(test_loader)\n",
    "    test_acc = correct / total\n",
    "    return test_loss, test_acc\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "best_val_acc = 0.0\n",
    "patience = 10\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer,device)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, criterion,device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # Early stopping\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        counter = 0\n",
    "        # Save best model - move to CPU first\n",
    "        torch.save(model.to('cpu').state_dict(), 'models/best_cnn_model_alphabet_both.pth')\n",
    "        model = model.to(device)  # Move back to MPS\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch+1}')\n",
    "            break\n",
    "\n",
    "model = model.to('cpu')\n",
    "model.load_state_dict(torch.load('models/best_cnn_model_alphabet_both.pth'))\n",
    "\n",
    "# Final evaluation on CPU\n",
    "_, test_acc = evaluate(model, test_loader, criterion, device='cpu')\n",
    "print(f'Final test accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_accs, label='Train')\n",
    "plt.plot(val_accs, label='Validation')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.show()\n",
    "\n",
    "# Save the label mapping for inference\n",
    "with open('models/label_map_alphabet_both.pickle', 'wb') as f:\n",
    "    pickle.dump({'label_map_alphabet': label_map, 'reverse_label_map_alphabet': reverse_label_map}, f)\n",
    "print(\"Model and label mapping saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935eb5eb",
   "metadata": {},
   "source": [
    "<h3>4. Live Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2325bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define CNN model class (must match your training architecture)\n",
    "class HandGestureCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(HandGestureCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 2), padding=(1, 0))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(3, 1), padding=(1, 0))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 1))\n",
    "\n",
    "        # Calculate size after convolutions and pooling\n",
    "        self.fc_input_size = 128 * 5 * 1\n",
    "\n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(-1, self.fc_input_size)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Load label mapping\n",
    "with open('models/label_map_alphabet_both.pickle', 'rb') as f:\n",
    "    label_info = pickle.load(f)\n",
    "    label_map = label_info['label_map_alphabet']\n",
    "    reverse_label_map = label_info['reverse_label_map_alphabet']\n",
    "\n",
    "# Load model\n",
    "num_classes = len(label_map)\n",
    "model = HandGestureCNN(num_classes)\n",
    "model.load_state_dict(torch.load('models/best_cnn_model_alphabet_both.pth'))\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize MediaPipe\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "# Use non-static mode for video\n",
    "hands = mp_hands.Hands(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5, max_num_hands=1)\n",
    "\n",
    "while True:\n",
    "    # Read frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    H, W, _ = frame.shape\n",
    "\n",
    "    # Convert to RGB for MediaPipe\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process with MediaPipe\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        # Get the first detected hand\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]\n",
    "\n",
    "        # Draw hand landmarks\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            hand_landmarks,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "        # Extract coordinates\n",
    "        x_coords = [landmark.x for landmark in hand_landmarks.landmark]\n",
    "        y_coords = [landmark.y for landmark in hand_landmarks.landmark]\n",
    "\n",
    "        # Normalize coordinates\n",
    "        x_min, x_max = min(x_coords), max(x_coords)\n",
    "        y_min, y_max = min(y_coords), max(y_coords)\n",
    "\n",
    "        # Create feature vector\n",
    "        data_aux = []\n",
    "        for i in range(len(hand_landmarks.landmark)):\n",
    "            # Normalize to [0,1] range within hand bounding box\n",
    "            norm_x = (hand_landmarks.landmark[i].x - x_min) / (x_max - x_min) if x_max > x_min else 0\n",
    "            norm_y = (hand_landmarks.landmark[i].y - y_min) / (y_max - y_min) if y_max > y_min else 0\n",
    "\n",
    "            data_aux.append(norm_x)\n",
    "            data_aux.append(norm_y)\n",
    "\n",
    "        try:\n",
    "            # Prepare input for CNN\n",
    "            input_tensor = np.array(data_aux).reshape(1, 1, 21, 2)\n",
    "            input_tensor = torch.FloatTensor(input_tensor)\n",
    "\n",
    "            # Make prediction\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_tensor)\n",
    "                probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                confidence, predicted = torch.max(probabilities, 1)\n",
    "\n",
    "                # Convert to numpy for display\n",
    "                predicted_class = predicted.item()\n",
    "                confidence_value = confidence.item()\n",
    "\n",
    "                # Get class name\n",
    "                prediction = reverse_label_map[predicted_class]\n",
    "\n",
    "                # Calculate bounding box coordinates\n",
    "                x1 = max(0, int(x_min * W) - 10)\n",
    "                y1 = max(0, int(y_min * H) - 10)\n",
    "                x2 = min(W, int(x_max * W) + 10)\n",
    "                y2 = min(H, int(y_max * H) + 10)\n",
    "                \n",
    "                # Draw bounding box\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                \n",
    "                # Prepare text with confidence\n",
    "                text = f\"{prediction} ({confidence_value:.2f})\"\n",
    "                \n",
    "                # Get text size for better positioning\n",
    "                text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]\n",
    "                \n",
    "                # Position text above the bounding box\n",
    "                text_x = x1\n",
    "                text_y = y1 - 10 if y1 - 10 > text_size[1] else y1 + text_size[1] + 10\n",
    "                \n",
    "                # Draw text background\n",
    "                cv2.rectangle(frame, \n",
    "                             (text_x, text_y - text_size[1] - 5),\n",
    "                             (text_x + text_size[0], text_y + 5),\n",
    "                             (0, 255, 0), -1)\n",
    "                \n",
    "                # Draw text\n",
    "                cv2.putText(frame, text, (text_x, text_y), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Prediction error: {e}\")\n",
    "\n",
    "    # Display frame\n",
    "    cv2.imshow('Hand Gesture Recognition (CNN)', frame)\n",
    "\n",
    "    # Exit on 'q' press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fde3f2",
   "metadata": {},
   "source": [
    "<h3>4. Upload Video Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ebd24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 video files to process\n",
      "\n",
      "[1/1] Processing: IMG_0412.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing IMG_0412.mp4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 691/691 [00:11<00:00, 60.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "L\n",
      "U\n",
      "A\n",
      " \n",
      " \n",
      "Completed in 11.41 seconds\n",
      "Detected sentence: ILUA  \n",
      "Output video saved to: output_folder/video_output_folder/processed_IMG_0412.mp4\n",
      "\n",
      "Processing complete! Results saved to output_folder/text_result/asl_recognition_results.json\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Define CNN model class (must match your training architecture)\n",
    "class HandGestureCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(HandGestureCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 2), padding=(1, 0))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(3, 1), padding=(1, 0))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 1))\n",
    "\n",
    "        # Calculate size after convolutions and pooling\n",
    "        self.fc_input_size = 128 * 5 * 1\n",
    "\n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(-1, self.fc_input_size)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def process_video(video_path, output_path=None):\n",
    "    # Load label mapping\n",
    "    with open('models/label_map_alphabet_both.pickle', 'rb') as f:\n",
    "        label_info = pickle.load(f)\n",
    "        label_map = label_info['label_map_alphabet']\n",
    "        reverse_label_map = label_info['reverse_label_map_alphabet']\n",
    "\n",
    "    # Load model\n",
    "    num_classes = len(label_map)\n",
    "    model = HandGestureCNN(num_classes)\n",
    "    model.load_state_dict(torch.load('models/best_cnn_model_alphabet_both.pth'))\n",
    "    model.eval()  # Set to evaluation mode\n",
    "\n",
    "    # Initialize video capture from file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Check if video opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return {\n",
    "            \"processed_video\": video_path,\n",
    "            \"output_video\": None,\n",
    "            \"status\": \"error\",\n",
    "            \"error_message\": \"Could not open video file\",\n",
    "            \"detected_word\": \"\",\n",
    "            \"frame_by_frame\": []\n",
    "        }\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Initialize MediaPipe\n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "    # Use non-static mode for video\n",
    "    hands = mp_hands.Hands(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5, max_num_hands=1)\n",
    "\n",
    "    # Set up video writer if output path is specified\n",
    "    out = None\n",
    "    if output_path:\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can change the codec as needed\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Variables for detecting stable letter periods\n",
    "    frame_results = []\n",
    "    letter_history = []\n",
    "    current_letter = None\n",
    "    letter_stable_count = 0\n",
    "    stable_threshold = max(int(fps * 0.4), 4)  # Require letter to be stable for 0.5 seconds or at least 5 frames\n",
    "    min_confidence = 0.7  # Minimum confidence to consider a prediction\n",
    "    \n",
    "    # Add text overlay with instructions\n",
    "    instruction_text = \"Please hold each sign for at least 0.5 seconds\"\n",
    "    \n",
    "    # Process each frame with progress bar\n",
    "    pbar = tqdm(total=total_frames, desc=f\"Processing {os.path.basename(video_path)}\")\n",
    "    \n",
    "    # Store detailed letter detections with timestamps\n",
    "    letter_detections = []\n",
    "    \n",
    "    # Counter for frames without any hand detection\n",
    "    no_hand_count = 0\n",
    "    pause_threshold = max(int(fps * 1.0), 10)  # 1 second of no hands means a word break\n",
    "    \n",
    "    while True:\n",
    "        # Read frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        H, W, _ = frame.shape\n",
    "        frame_number = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "        frame_time = frame_number / fps  # Time in seconds\n",
    "\n",
    "        # Convert to RGB for MediaPipe\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process with MediaPipe\n",
    "        results = hands.process(frame_rgb)\n",
    "        \n",
    "        current_prediction = None\n",
    "        current_confidence = 0\n",
    "        \n",
    "        # Add instruction text to the frame\n",
    "        cv2.putText(frame, instruction_text, (10, H - 20), \n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            no_hand_count = 0  # Reset counter when hand is detected\n",
    "            \n",
    "            # Get the first detected hand\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "\n",
    "            # Draw hand landmarks\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "            # Extract coordinates\n",
    "            x_coords = [landmark.x for landmark in hand_landmarks.landmark]\n",
    "            y_coords = [landmark.y for landmark in hand_landmarks.landmark]\n",
    "\n",
    "            # Normalize coordinates\n",
    "            x_min, x_max = min(x_coords), max(x_coords)\n",
    "            y_min, y_max = min(y_coords), max(y_coords)\n",
    "\n",
    "            # Create feature vector\n",
    "            data_aux = []\n",
    "            for i in range(len(hand_landmarks.landmark)):\n",
    "                # Normalize to [0,1] range within hand bounding box\n",
    "                norm_x = (hand_landmarks.landmark[i].x - x_min) / (x_max - x_min) if x_max > x_min else 0\n",
    "                norm_y = (hand_landmarks.landmark[i].y - y_min) / (y_max - y_min) if y_max > y_min else 0\n",
    "\n",
    "                data_aux.append(norm_x)\n",
    "                data_aux.append(norm_y)\n",
    "\n",
    "            try:\n",
    "                # Prepare input for CNN\n",
    "                input_tensor = np.array(data_aux).reshape(1, 1, 21, 2)\n",
    "                input_tensor = torch.FloatTensor(input_tensor)\n",
    "\n",
    "                # Make prediction\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(input_tensor)\n",
    "                    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                    confidence, predicted = torch.max(probabilities, 1)\n",
    "\n",
    "                    # Convert to numpy for display\n",
    "                    predicted_class = predicted.item()\n",
    "                    confidence_value = confidence.item()\n",
    "\n",
    "                    # Get class name\n",
    "                    prediction = reverse_label_map[predicted_class]\n",
    "                    current_prediction = prediction\n",
    "                    current_confidence = confidence_value\n",
    "\n",
    "                    # Update letter history for stability tracking\n",
    "                    if confidence_value >= min_confidence:\n",
    "                        letter_history.append((prediction, confidence_value))\n",
    "                        # Keep history to a reasonable size\n",
    "                        if len(letter_history) > stable_threshold * 2:\n",
    "                            letter_history = letter_history[-stable_threshold * 2:]\n",
    "                    \n",
    "                    # Calculate bounding box coordinates\n",
    "                    x1 = max(0, int(x_min * W) - 10)\n",
    "                    y1 = max(0, int(y_min * H) - 10)\n",
    "                    x2 = min(W, int(x_max * W) + 10)\n",
    "                    y2 = min(H, int(y_max * H) + 10)\n",
    "                    \n",
    "                    # Draw bounding box\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    \n",
    "                    # Prepare text with confidence\n",
    "                    text = f\"{prediction} ({confidence_value:.2f})\"\n",
    "                    \n",
    "                    # Get text size for better positioning\n",
    "                    text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]\n",
    "                    \n",
    "                    # Position text above the bounding box\n",
    "                    text_x = x1\n",
    "                    text_y = y1 - 10 if y1 - 10 > text_size[1] else y1 + text_size[1] + 10\n",
    "                    \n",
    "                    # Draw text background\n",
    "                    cv2.rectangle(frame, \n",
    "                                (text_x, text_y - text_size[1] - 5),\n",
    "                                (text_x + text_size[0], text_y + 5),\n",
    "                                (0, 255, 0), -1)\n",
    "                    \n",
    "                    # Draw text\n",
    "                    cv2.putText(frame, text, (text_x, text_y), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Prediction error: {e}\")\n",
    "        else:\n",
    "            # No hand detected\n",
    "            no_hand_count += 1\n",
    "            letter_history = []  # Clear history when no hand is detected\n",
    "        \n",
    "        # Stability analysis\n",
    "        if len(letter_history) >= stable_threshold:\n",
    "            # Check if the last N predictions are the same\n",
    "            recent_letters = [item[0] for item in letter_history[-stable_threshold:]]\n",
    "            most_common = max(set(recent_letters), key=recent_letters.count)\n",
    "            \n",
    "            # If we have a consistent prediction\n",
    "            if recent_letters.count(most_common) >= stable_threshold * 0.8:  # 80% agreement\n",
    "                # If this is a new stable letter (different from current)\n",
    "                if most_common != current_letter:\n",
    "                    if current_letter is not None:\n",
    "                        # Record the previously stable letter\n",
    "                        letter_detections.append({\n",
    "                            \"letter\": current_letter,\n",
    "                            \"confidence\": letter_history[-1][1],\n",
    "                            \"time\": frame_time,\n",
    "                            \"frame\": frame_number\n",
    "                        })\n",
    "                    \n",
    "                    # Set new current letter\n",
    "                    current_letter = most_common\n",
    "                    letter_stable_count = 1\n",
    "                else:\n",
    "                    # Still the same letter, just update count\n",
    "                    letter_stable_count += 1\n",
    "        \n",
    "        # Check for word break (pause in signing)\n",
    "        if no_hand_count >= pause_threshold and current_letter is not None:\n",
    "            # Add a space to indicate word break\n",
    "            letter_detections.append({\n",
    "                \"letter\": \" \",\n",
    "                \"confidence\": 1.0,\n",
    "                \"time\": frame_time,\n",
    "                \"frame\": frame_number,\n",
    "                \"is_word_break\": True\n",
    "            })\n",
    "            current_letter = None\n",
    "            letter_stable_count = 0\n",
    "        \n",
    "        # Add frame counter and current letter status\n",
    "        text_status = f\"Frame: {frame_number}/{total_frames}\"\n",
    "        if current_letter:\n",
    "            text_status += f\" | Current: {current_letter} ({letter_stable_count})\"\n",
    "            \n",
    "        cv2.putText(frame, text_status, (10, 30), \n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Save frame result for detailed analysis\n",
    "        frame_results.append((frame_number, current_prediction, current_confidence))\n",
    "        \n",
    "        # Write the frame to output video if specified\n",
    "        if out:\n",
    "            out.write(frame)\n",
    "            \n",
    "        # Update progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "    # Close progress bar\n",
    "    pbar.close()\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    if out:\n",
    "        out.release()\n",
    "    \n",
    "    # Process letter detections to create a clean sentence\n",
    "    # First, filter out low confidence or sporadic detections\n",
    "    filtered_detections = []\n",
    "    prev_letter = None\n",
    "    for detection in letter_detections:\n",
    "        letter = detection[\"letter\"]\n",
    "        print(letter)\n",
    "        # Skip if it's the same as previous (avoid repetition)\n",
    "        if letter == prev_letter and letter != \" \":\n",
    "            continue\n",
    "            \n",
    "        # Add to filtered list\n",
    "        filtered_detections.append(detection)\n",
    "        prev_letter = letter\n",
    "    \n",
    "    # Create the detected word/sentence\n",
    "    detected_sentence = ''.join([d[\"letter\"] for d in filtered_detections])\n",
    "    \n",
    "    # Generate summary\n",
    "    summary = {\n",
    "        \"processed_video\": video_path,\n",
    "        \"output_video\": output_path,\n",
    "        \"status\": \"success\",\n",
    "        \"detected_sentence\": detected_sentence,\n",
    "        \"letter_detections\": [\n",
    "            {\n",
    "                \"letter\": d[\"letter\"],\n",
    "                \"confidence\": round(float(d[\"confidence\"]), 2),\n",
    "                \"time_seconds\": round(d[\"time\"], 2),\n",
    "                \"frame\": d[\"frame\"],\n",
    "                \"is_word_break\": d.get(\"is_word_break\", False)\n",
    "            }\n",
    "            for d in filtered_detections\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def process_folder(input_folder, output_video_folder, output_text_folder):\n",
    "    # Create output folders if they don't exist\n",
    "    os.makedirs(output_video_folder, exist_ok=True)\n",
    "    os.makedirs(output_text_folder, exist_ok=True)\n",
    "    \n",
    "    # Get all video files in input folder\n",
    "    video_extensions = ['.mp4', '.avi', '.mkv', '.wmv']  # Removed .mov since it may not be supported\n",
    "    video_files = []\n",
    "    \n",
    "    for ext in video_extensions:\n",
    "        video_files.extend(list(Path(input_folder).glob(f'**/*{ext}')))\n",
    "    \n",
    "    if not video_files:\n",
    "        print(f\"No video files found in {input_folder}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Found {len(video_files)} video files to process\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Process each video\n",
    "    for i, video_path in enumerate(video_files):\n",
    "        video_path_str = str(video_path)\n",
    "        print(f\"\\n[{i+1}/{len(video_files)}] Processing: {video_path.name}\")\n",
    "        \n",
    "        # Create output path for the video\n",
    "        output_path = os.path.join(output_video_folder, f\"processed_{os.path.basename(video_path_str)}\")\n",
    "        \n",
    "        # Process the video\n",
    "        start_time = time.time()\n",
    "        result = process_video(video_path_str, output_path)\n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        # Add processing time to results\n",
    "        result[\"processing_time_seconds\"] = processing_time\n",
    "        \n",
    "        # Add result to collection\n",
    "        all_results.append(result)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"Completed in {processing_time:.2f} seconds\")\n",
    "        print(f\"Detected sentence: {result['detected_sentence']}\")\n",
    "        print(f\"Output video saved to: {output_path}\")\n",
    "    \n",
    "    # Save a single consolidated JSON result\n",
    "    results_path = os.path.join(output_text_folder, \"asl_recognition_results.json\")\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump({\n",
    "            \"total_videos\": len(video_files),\n",
    "            \"processing_date\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"results\": all_results\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nProcessing complete! Results saved to {results_path}\")\n",
    "    return all_results\n",
    "\n",
    "def main():\n",
    "    # Replace the main() function and the if __name__ == \"__main__\": block with this:\n",
    "\n",
    "# Directly specify your folder paths here\n",
    "    input_folder = \"input_video\"  # Replace with your actual input folder path\n",
    "    output_folder = \"output_folder\"  # Replace with your desired output folder\n",
    "\n",
    "    # Create subdirectories for videos and text results\n",
    "    output_video_folder = os.path.join(output_folder, \"video_output_folder\")\n",
    "    output_text_folder = os.path.join(output_folder, \"text_result\")\n",
    "\n",
    "    # Process all videos in the folder\n",
    "    results = process_folder(input_folder, output_video_folder, output_text_folder)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "try_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
