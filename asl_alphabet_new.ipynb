{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80143044",
   "metadata": {},
   "source": [
    "<h2>1. Collecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22abb82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      " - Classes: ['Z']\n",
      " - Sequences per class: 10\n",
      " - Frames per sequence: 20\n",
      " - Target capture duration: 0.6 seconds\n",
      " - Calculated delay between frames: 30 ms\n",
      "--------------------\n",
      "Controls:\n",
      "  S: Start recording sequence for the current class\n",
      "  Q: Quit collecting for the current class (move to next)\n",
      "  Esc: Exit the program entirely\n",
      "--------------------\n",
      "\n",
      "Collecting data for class: Z\n",
      " - Starting from sequence number: 0\n",
      " - Will collect 10 new sequences (up to sequence 9)\n",
      "  Starting sequence 0...\n",
      "  Get Ready...\n",
      "  Finished sequence 0. Saved 20 frames in ./data_alphabet_sequences/Z/000\n",
      "  Starting sequence 1...\n",
      "  Get Ready...\n",
      "  Finished sequence 1. Saved 20 frames in ./data_alphabet_sequences/Z/001\n",
      "  Starting sequence 2...\n",
      "  Get Ready...\n",
      "  Finished sequence 2. Saved 20 frames in ./data_alphabet_sequences/Z/002\n",
      "  Starting sequence 3...\n",
      "  Get Ready...\n",
      "  Finished sequence 3. Saved 20 frames in ./data_alphabet_sequences/Z/003\n",
      "  Starting sequence 4...\n",
      "  Get Ready...\n",
      "  Finished sequence 4. Saved 20 frames in ./data_alphabet_sequences/Z/004\n",
      "  Starting sequence 5...\n",
      "  Get Ready...\n",
      "  Finished sequence 5. Saved 20 frames in ./data_alphabet_sequences/Z/005\n",
      "  Starting sequence 6...\n",
      "  Get Ready...\n",
      "  Finished sequence 6. Saved 20 frames in ./data_alphabet_sequences/Z/006\n",
      "  Starting sequence 7...\n",
      "  Get Ready...\n",
      "  Finished sequence 7. Saved 20 frames in ./data_alphabet_sequences/Z/007\n",
      "  Starting sequence 8...\n",
      "  Get Ready...\n",
      "  Finished sequence 8. Saved 20 frames in ./data_alphabet_sequences/Z/008\n",
      "  Starting sequence 9...\n",
      "  Get Ready...\n",
      "  Finished sequence 9. Saved 20 frames in ./data_alphabet_sequences/Z/009\n",
      "\n",
      "Data collection finished or exited.\n",
      "Webcam released.\n",
      "Attempting to close OpenCV window...\n",
      "OpenCV windows closed.\n",
      "Resources released.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "#import shutil # Uncomment if you want to enable deleting partial sequences on abort\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_DIR = './data_alphabet_sequences' # Store sequences in a new directory\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "\n",
    "# Define the classes you want to collect\n",
    "# classes = ['A','B','C','D','E','F','G','H','I','J','K','L','M',\n",
    "#            'N','O','P','Q','R','S','T','U','V','W','X','Y','Z',\n",
    "#            'Hello','My','Engineer','Name','Yes','No','Me'] \n",
    "NUM_SEQUENCES_PER_CLASS = 10  # How many sequences (examples) to collect for each class\n",
    "SEQUENCE_LENGTH = 10          # Total frames to capture per sequence\n",
    "CAPTURE_DURATION = 0.6        # Total duration to capture sequence in seconds (0.6s for comfortable signing)\n",
    "# Ensure delay is at least 1ms\n",
    "CAPTURE_DELAY_MS = max(1, int((CAPTURE_DURATION * 1000) / SEQUENCE_LENGTH))  # Calculate delay between frames\n",
    "WINDOW_NAME = 'Data Collection' # Define window name\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\" - Classes: {classes}\")\n",
    "print(f\" - Sequences per class: {NUM_SEQUENCES_PER_CLASS}\")\n",
    "print(f\" - Frames per sequence: {SEQUENCE_LENGTH}\")\n",
    "print(f\" - Target capture duration: {CAPTURE_DURATION} seconds\")\n",
    "print(f\" - Calculated delay between frames: {CAPTURE_DELAY_MS} ms\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# --- Main Collection Logic ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "# Optional: Set resolution if needed\n",
    "# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "print(\"Controls:\")\n",
    "print(\"  S: Start recording sequence for the current class\")\n",
    "print(\"  Q: Quit collecting for the current class (move to next)\")\n",
    "print(\"  Esc: Exit the program entirely\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "exit_program = False # Flag to signal exiting the entire script\n",
    "\n",
    "for sign_class in classes:\n",
    "    if exit_program: # Check if we need to exit before starting next class\n",
    "        break\n",
    "\n",
    "    class_path = os.path.join(DATA_DIR, sign_class)\n",
    "    if not os.path.exists(class_path):\n",
    "        os.makedirs(class_path)\n",
    "\n",
    "    print(f'\\nCollecting data for class: {sign_class}')\n",
    "\n",
    "    # Find the highest sequence number in existing folders to continue from there\n",
    "    existing_sequences = []\n",
    "    if os.path.exists(class_path):\n",
    "        for item in os.listdir(class_path):\n",
    "            # Check if item is a directory and its name is a number\n",
    "            if os.path.isdir(os.path.join(class_path, item)) and item.isdigit():\n",
    "                try: # Add try-except for robustness\n",
    "                    existing_sequences.append(int(item))\n",
    "                except ValueError:\n",
    "                    pass # Ignore non-numeric folders\n",
    "\n",
    "    # Determine starting sequence number\n",
    "    starting_sequence_num = max(existing_sequences) + 1 if existing_sequences else 0\n",
    "    target_sequence_count = starting_sequence_num + NUM_SEQUENCES_PER_CLASS\n",
    "\n",
    "    print(f\" - Starting from sequence number: {starting_sequence_num}\")\n",
    "    print(f\" - Will collect {NUM_SEQUENCES_PER_CLASS} new sequences (up to sequence {target_sequence_count - 1})\")\n",
    "\n",
    "    sequence_counter = starting_sequence_num\n",
    "\n",
    "    # Loop for collecting sequences for the current class\n",
    "    while sequence_counter < target_sequence_count:\n",
    "        # Display instructions and wait for trigger\n",
    "        instruction_text = f\"Class: {sign_class} | Next Seq: {sequence_counter} | Press 'S' | 'Q' Quit Class | 'Esc' Exit\"\n",
    "        recording_active = False\n",
    "\n",
    "        while True: # Inner loop: Wait for user action (S, Q, or Esc)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Failed to capture frame.\")\n",
    "                time.sleep(0.1)\n",
    "                continue\n",
    "\n",
    "            # Display instructions on the frame\n",
    "            cv2.putText(frame, instruction_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame, f\"Target: {SEQUENCE_LENGTH} frames in {CAPTURE_DURATION}s\",\n",
    "                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.imshow(WINDOW_NAME, frame)\n",
    "\n",
    "            key = cv2.waitKey(30) & 0xFF  # More responsive wait while idle\n",
    "\n",
    "            if key == 27: # ESC key pressed\n",
    "                print(\"Escape key pressed. Exiting program.\")\n",
    "                exit_program = True\n",
    "                break # Exit inner loop\n",
    "\n",
    "            if key == ord('q'):\n",
    "                print(f\"Quitting collection for class {sign_class}.\")\n",
    "                sequence_counter = target_sequence_count # Force exit outer loop for this class\n",
    "                break # Exit the inner waiting loop\n",
    "\n",
    "            if key == ord('s'):\n",
    "                recording_active = True\n",
    "                break # Exit the inner waiting loop to start recording\n",
    "\n",
    "        # Check if we need to exit the program or the class loop\n",
    "        if exit_program:\n",
    "            break\n",
    "        # This handles quitting the class with 'Q' or finishing all sequences\n",
    "        if sequence_counter >= target_sequence_count and not recording_active:\n",
    "             break\n",
    "\n",
    "        # Start recording the sequence if triggered\n",
    "        if recording_active:\n",
    "            print(f\"  Starting sequence {sequence_counter}...\")\n",
    "            sequence_path = os.path.join(class_path, f\"{sequence_counter:03d}\") # Padded sequence number\n",
    "            os.makedirs(sequence_path, exist_ok=True)\n",
    "\n",
    "            # --- Modified Countdown ---\n",
    "            # Display \"GET READY!\" and wait 0.5 seconds before starting capture\n",
    "            print(\"  Get Ready...\") # Console message\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                cv2.putText(frame, \"GET READY!\", (frame.shape[1]//4, frame.shape[0]//2),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "                cv2.imshow(WINDOW_NAME, frame)\n",
    "                cv2.waitKey(500) # Wait 0.5 seconds\n",
    "            # --- End Modified Countdown ---\n",
    "\n",
    "\n",
    "            # --- Frame capture loop for the sequence ---\n",
    "            sequence_aborted = False\n",
    "            # start_time = time.time() # Keep if you want to display elapsed time\n",
    "\n",
    "            for frame_num in range(SEQUENCE_LENGTH):\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(f\"Error: Failed to capture frame during sequence {sequence_counter}, frame {frame_num}.\")\n",
    "                    sequence_aborted = True\n",
    "                    break # Exit frame capture loop\n",
    "\n",
    "                # --- Display recording status (Optional but helpful) ---\n",
    "                # elapsed = time.time() - start_time\n",
    "                # cv2.putText(frame, f\"REC Seq {sequence_counter} Frame {frame_num+1}/{SEQUENCE_LENGTH}\",\n",
    "                #            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                # cv2.putText(frame, f\"Time: {elapsed:.2f}s / {CAPTURE_DURATION}s\",\n",
    "                #            (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                # --- Show progress bar ---\n",
    "                progress_width = int(((frame_num + 1) / SEQUENCE_LENGTH) * frame.shape[1] * 0.8) # Use frame_num+1 for progress\n",
    "                cv2.rectangle(frame, (int(frame.shape[1]*0.1), frame.shape[0]-30),\n",
    "                             (int(frame.shape[1]*0.1) + progress_width, frame.shape[0]-20), (0, 255, 0), -1)\n",
    "\n",
    "                cv2.imshow(WINDOW_NAME, frame)\n",
    "\n",
    "                # --- Save the frame ---\n",
    "                frame_filename = os.path.join(sequence_path, f\"{frame_num:03d}.jpg\") # Padded frame number\n",
    "                cv2.imwrite(frame_filename, frame) # This still takes time! Consider deferring if timing is critical\n",
    "\n",
    "                # --- Wait and check for abort keys ---\n",
    "                key_capture = cv2.waitKey(CAPTURE_DELAY_MS) & 0xFF\n",
    "\n",
    "                if key_capture == ord('q'):\n",
    "                    print(\"Warning: Sequence recording aborted by user (Q pressed).\")\n",
    "                    sequence_aborted = True\n",
    "                    # Consider deleting the partially recorded sequence folder here if desired\n",
    "                    # import shutil\n",
    "                    # if os.path.exists(sequence_path): shutil.rmtree(sequence_path)\n",
    "                    sequence_counter = target_sequence_count # Force quit class\n",
    "                    break\n",
    "                elif key_capture == 27: # ESC key pressed\n",
    "                     print(\"Warning: Sequence recording aborted by user (Esc pressed). Exiting program.\")\n",
    "                     sequence_aborted = True\n",
    "                     # Consider deleting the partially recorded sequence folder here if desired\n",
    "                     # import shutil\n",
    "                     # if os.path.exists(sequence_path): shutil.rmtree(sequence_path)\n",
    "                     exit_program = True # Signal exit for outer loops\n",
    "                     break\n",
    "            # --- End Frame Capture Loop ---\n",
    "\n",
    "\n",
    "            # --- Post-Capture Actions ---\n",
    "            if exit_program: # Check if user pressed Esc mid-sequence\n",
    "                 print(f\"  Sequence {sequence_counter} aborted due to exit request.\")\n",
    "                 break # Exit class loop\n",
    "\n",
    "            if not sequence_aborted:\n",
    "                print(f\"  Finished sequence {sequence_counter}. Saved {SEQUENCE_LENGTH} frames in {sequence_path}\")\n",
    "                # --- !!! Increment the counter !!! ---\n",
    "                sequence_counter += 1\n",
    "                # --- Add a small pause before the next prompt ---\n",
    "                time.sleep(0.5)\n",
    "            else:\n",
    "                # Handle sequence aborted by 'q' (message already printed)\n",
    "                # sequence_counter is already set to target_sequence_count to exit class loop\n",
    "                 print(f\"  Sequence {sequence_counter} aborted by user ('Q').\")\n",
    "                 pass # Continue to next iteration of class loop (which will exit)\n",
    "\n",
    "\n",
    "    # End of sequence collection loop for one class\n",
    "    if exit_program: # Check if we need to exit after finishing/quitting a class\n",
    "        break\n",
    "\n",
    "# --- Cleanup ---\n",
    "print(\"\\nData collection finished or exited.\")\n",
    "if cap.isOpened(): cap.release() # Ensure release happens\n",
    "print(\"Webcam released.\")\n",
    "\n",
    "# Explicitly destroy the named window\n",
    "print(\"Attempting to close OpenCV window...\")\n",
    "for i in range(5): # Loop helps ensure window closes on some systems\n",
    "    cv2.destroyWindow(WINDOW_NAME)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "# Fallback for any other windows\n",
    "cv2.destroyAllWindows()\n",
    "for i in range(5): cv2.waitKey(1) # Help process closing events\n",
    "\n",
    "print(\"OpenCV windows closed.\")\n",
    "print(\"Resources released.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51b8b25",
   "metadata": {},
   "source": [
    "<h2>2. Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cb72fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746305788.224182 26907441 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Pro\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sequences from: ./data_alphabet_sequences\n",
      "Target classes: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'Hello', 'My', 'Engineer', 'Name', 'Yes', 'No', 'Me']\n",
      "Sequence Length: 10\n",
      "Target Features per Frame: 84\n",
      "------------------------------\n",
      "\n",
      "Processing Class: A...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for A:   0%|          | 0/10 [00:00<?, ?seq/s]W0000 00:00:1746305788.231767 27770811 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746305788.236452 27770812 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "  Sequences for A: 100%|██████████| 10/10 [00:02<00:00,  4.05seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: B...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for B: 100%|██████████| 10/10 [00:02<00:00,  4.18seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: C...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for C: 100%|██████████| 10/10 [00:02<00:00,  4.21seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: D...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for D: 100%|██████████| 10/10 [00:02<00:00,  4.19seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: E...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for E: 100%|██████████| 10/10 [00:02<00:00,  4.16seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: F...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for F: 100%|██████████| 10/10 [00:02<00:00,  4.06seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: G...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for G: 100%|██████████| 10/10 [00:02<00:00,  4.08seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: H...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for H: 100%|██████████| 10/10 [00:02<00:00,  4.06seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: I...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for I: 100%|██████████| 10/10 [00:02<00:00,  3.98seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: J...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for J: 100%|██████████| 10/10 [00:02<00:00,  4.05seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: K...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for K: 100%|██████████| 10/10 [00:02<00:00,  3.94seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: L...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for L: 100%|██████████| 10/10 [00:02<00:00,  4.04seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: M...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for M: 100%|██████████| 10/10 [00:02<00:00,  4.01seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: N...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for N: 100%|██████████| 10/10 [00:02<00:00,  3.93seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: O...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for O: 100%|██████████| 10/10 [00:02<00:00,  4.04seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: P...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for P: 100%|██████████| 10/10 [00:02<00:00,  3.96seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: Q...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for Q: 100%|██████████| 10/10 [00:02<00:00,  3.99seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: R...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for R: 100%|██████████| 10/10 [00:02<00:00,  3.95seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: S...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for S: 100%|██████████| 10/10 [00:02<00:00,  3.88seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: T...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for T: 100%|██████████| 10/10 [00:02<00:00,  3.81seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: U...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for U: 100%|██████████| 10/10 [00:02<00:00,  3.96seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: V...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for V: 100%|██████████| 10/10 [00:02<00:00,  3.94seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: W...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for W: 100%|██████████| 10/10 [00:02<00:00,  3.92seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: X...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for X: 100%|██████████| 10/10 [00:02<00:00,  3.97seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: Y...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for Y: 100%|██████████| 10/10 [00:02<00:00,  3.97seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: Z...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for Z: 100%|██████████| 10/10 [00:02<00:00,  3.65seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: Hello...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for Hello: 100%|██████████| 10/10 [00:02<00:00,  3.81seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: My...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for My: 100%|██████████| 10/10 [00:02<00:00,  3.88seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: Engineer...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for Engineer: 100%|██████████| 10/10 [00:02<00:00,  4.22seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: Name...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for Name: 100%|██████████| 10/10 [00:02<00:00,  4.00seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: Yes...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for Yes: 100%|██████████| 10/10 [00:02<00:00,  3.78seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: No...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for No: 100%|██████████| 10/10 [00:02<00:00,  3.88seq/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: Me...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for Me: 100%|██████████| 10/10 [00:02<00:00,  3.75seq/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------\n",
      "Processing Summary:\n",
      "  Total sequences processed (before mirroring): 330\n",
      "  Total sequences skipped (frame errors/count mismatch): 0\n",
      "  Total samples generated (including mirrored): 660\n",
      "  Total labels generated: 660\n",
      "\n",
      "Final data array shape: (660, 10, 84)\n",
      "Final label array shape: (660,)\n",
      "\n",
      "Saving shuffled dataset to: ./train_data_set/asl_sequences_dataset.pickle\n",
      "Dataset saved successfully.\n",
      "\n",
      "Dataset creation script finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm # For progress bar\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_DIR = './data_alphabet_sequences' # Directory where sequence folders are stored\n",
    "OUTPUT_PICKLE_FILE = './train_data_set/asl_sequences_dataset.pickle' # Output file path\n",
    "SEQUENCE_LENGTH = 10          # Must match the collection script (e.g., 30 frames)\n",
    "NUM_LANDMARKS = 21            # Number of landmarks per hand\n",
    "FEATURES_PER_LANDMARK = 2     # Using x, y coordinates\n",
    "FEATURES_PER_HAND = NUM_LANDMARKS * FEATURES_PER_LANDMARK # Should be 42\n",
    "TARGET_FEATURES_PER_FRAME = FEATURES_PER_HAND * 2         # Target 84 features (for two hands)\n",
    "\n",
    "# Define the classes you want to process (start with 5 for testing)\n",
    "# Make sure these match folder names in DATA_DIR\n",
    "# classes_to_process = ['A', 'B', 'C', 'D', 'E']\n",
    "# Or use the full list if data exists:\n",
    "#classes_to_process = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','Hello','Me','Yes','No','Help','Please','Thank_You','Want','What','Again','Eat','More','Go_to','Fine','Like','Learn','Finish','Name','How','You','Nice','Meet']\n",
    "classes_to_process = ['A','B','C','D','E','F','G','H','I','J','K','L','M',\n",
    "           'N','O','P','Q','R','S','T','U','V','W','X','Y','Z'\n",
    "           'Hello','My','Engineer','Name','Yes','No','Me']\n",
    "# --- MediaPipe Initialization ---\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,       # Process video frames\n",
    "    max_num_hands=2,               # Detect up to two hands\n",
    "    min_detection_confidence=0.5,  # Adjust as needed\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def normalize_landmarks(landmarks, image_shape):\n",
    "    \"\"\"\n",
    "    Normalizes landmarks relative to the hand's bounding box.\n",
    "    Returns a list of 42 features or None if normalization fails.\n",
    "    \"\"\"\n",
    "    if not landmarks:\n",
    "        return None\n",
    "\n",
    "    x_coords = [lm.x * image_shape[1] for lm in landmarks.landmark] # Convert to pixel coords\n",
    "    y_coords = [lm.y * image_shape[0] for lm in landmarks.landmark]\n",
    "\n",
    "    if not x_coords or not y_coords:\n",
    "        return None\n",
    "\n",
    "    x_min, x_max = min(x_coords), max(x_coords)\n",
    "    y_min, y_max = min(y_coords), max(y_coords)\n",
    "\n",
    "    # Avoid division by zero for degenerate bounding boxes\n",
    "    if x_max == x_min or y_max == y_min:\n",
    "        # print(\"Warning: Degenerate bounding box detected.\")\n",
    "        return None # Indicate failure\n",
    "\n",
    "    normalized_features = []\n",
    "    for lm in landmarks.landmark:\n",
    "        # Normalize relative to the bounding box\n",
    "        norm_x = (lm.x * image_shape[1] - x_min) / (x_max - x_min)\n",
    "        norm_y = (lm.y * image_shape[0] - y_min) / (y_max - y_min)\n",
    "        normalized_features.extend([norm_x, norm_y])\n",
    "\n",
    "    if len(normalized_features) != FEATURES_PER_HAND:\n",
    "        print(f\"Warning: Incorrect feature count after normalization: {len(normalized_features)}\")\n",
    "        return None\n",
    "\n",
    "    return normalized_features\n",
    "\n",
    "def mirror_features(features_42):\n",
    "    \"\"\"Mirrors a 42-feature vector horizontally.\"\"\"\n",
    "    if features_42 is None or len(features_42) != FEATURES_PER_HAND:\n",
    "        return None # Or return zeros? Let's return None for clarity\n",
    "\n",
    "    mirrored = []\n",
    "    for i in range(0, FEATURES_PER_HAND, 2): # Step through x, y pairs\n",
    "        norm_x = features_42[i]\n",
    "        norm_y = features_42[i+1]\n",
    "        mirrored_norm_x = 1.0 - norm_x # Flip normalized x\n",
    "        mirrored.extend([mirrored_norm_x, norm_y])\n",
    "    return mirrored\n",
    "\n",
    "# --- Main Processing Logic ---\n",
    "\n",
    "all_sequences_data = []\n",
    "all_sequences_labels = []\n",
    "processed_sequences_count = 0\n",
    "skipped_sequences_count = 0\n",
    "\n",
    "print(f\"Processing sequences from: {DATA_DIR}\")\n",
    "print(f\"Target classes: {classes_to_process}\")\n",
    "print(f\"Sequence Length: {SEQUENCE_LENGTH}\")\n",
    "print(f\"Target Features per Frame: {TARGET_FEATURES_PER_FRAME}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Iterate through specified class directories\n",
    "for sign_class in classes_to_process:\n",
    "    class_path = os.path.join(DATA_DIR, sign_class)\n",
    "    print(f\"\\nProcessing Class: {sign_class}...\")\n",
    "\n",
    "    if not os.path.isdir(class_path):\n",
    "        print(f\"  Warning: Directory not found for class '{sign_class}'. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Iterate through sequence folders (e.g., '000', '001', ...)\n",
    "    sequence_folders = sorted([f for f in os.listdir(class_path) if os.path.isdir(os.path.join(class_path, f)) and f.isdigit()])\n",
    "\n",
    "    if not sequence_folders:\n",
    "        print(f\"  No sequence folders found in {class_path}. Skipping class.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"  Found {len(sequence_folders)} sequence folders.\")\n",
    "\n",
    "    for seq_folder_name in tqdm(sequence_folders, desc=f\"  Sequences for {sign_class}\", unit=\"seq\"):\n",
    "        seq_path = os.path.join(class_path, seq_folder_name)\n",
    "        sequence_frame_features = [] # Store features for all frames in this sequence\n",
    "\n",
    "        frame_files = sorted([f for f in os.listdir(seq_path) if f.lower().endswith('.jpg') or f.lower().endswith('.png')])\n",
    "\n",
    "        # Ensure frames are processed in order (000.jpg, 001.jpg, ...)\n",
    "        frame_files.sort(key=lambda x: int(os.path.splitext(x)[0]))\n",
    "\n",
    "        if len(frame_files) != SEQUENCE_LENGTH:\n",
    "             print(f\"\\n  Warning: Sequence {seq_folder_name} in class {sign_class} has {len(frame_files)} frames, expected {SEQUENCE_LENGTH}. Skipping.\")\n",
    "             skipped_sequences_count += 1\n",
    "             continue # Skip this sequence if frame count is wrong\n",
    "\n",
    "        valid_sequence = True\n",
    "        for frame_filename in frame_files:\n",
    "            frame_path = os.path.join(seq_path, frame_filename)\n",
    "            frame = cv2.imread(frame_path)\n",
    "\n",
    "            if frame is None:\n",
    "                print(f\"\\n  Warning: Failed to read frame {frame_path}. Skipping sequence {seq_folder_name}.\")\n",
    "                valid_sequence = False\n",
    "                break # Skip rest of the frames in this sequence\n",
    "\n",
    "            # Process frame with MediaPipe\n",
    "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image_rgb.flags.writeable = False # Optimize\n",
    "            results = hands.process(image_rgb)\n",
    "            image_rgb.flags.writeable = True\n",
    "\n",
    "            # Initialize frame features with zeros (padding)\n",
    "            frame_features = np.zeros(TARGET_FEATURES_PER_FRAME, dtype=np.float32)\n",
    "            normalized_hands = [] # Store normalized features for detected hands\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                # Normalize landmarks for each detected hand\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    norm_features = normalize_landmarks(hand_landmarks, frame.shape)\n",
    "                    if norm_features:\n",
    "                        normalized_hands.append(norm_features)\n",
    "\n",
    "                # Sort hands by horizontal position (leftmost first) - Optional but good practice\n",
    "                # This requires getting a representative point like the wrist (landmark 0)\n",
    "                # For simplicity now, just take first two detected if more than 2\n",
    "                normalized_hands = normalized_hands[:2] # Max 2 hands\n",
    "\n",
    "                # Assign features based on number of hands detected\n",
    "                if len(normalized_hands) == 1:\n",
    "                    # Place the single hand in the first 42 slots\n",
    "                    frame_features[:FEATURES_PER_HAND] = normalized_hands[0]\n",
    "                elif len(normalized_hands) == 2:\n",
    "                    # Decide order (e.g., based on x-coord of wrist)\n",
    "                    # For now, just assign first detected to first slot, second to second\n",
    "                    frame_features[:FEATURES_PER_HAND] = normalized_hands[0]\n",
    "                    frame_features[FEATURES_PER_HAND:] = normalized_hands[1]\n",
    "\n",
    "            # Append the (potentially padded) 84 features for this frame\n",
    "            sequence_frame_features.append(frame_features)\n",
    "\n",
    "        # After processing all frames for the sequence\n",
    "        if valid_sequence and len(sequence_frame_features) == SEQUENCE_LENGTH:\n",
    "            processed_sequences_count += 1\n",
    "\n",
    "            # 1. Add the original sequence\n",
    "            all_sequences_data.append(sequence_frame_features)\n",
    "            all_sequences_labels.append(sign_class)\n",
    "\n",
    "            # 2. Create and add the mirrored sequence\n",
    "            mirrored_sequence = []\n",
    "            for frame_vec_84 in sequence_frame_features:\n",
    "                # Separate the 84 features into two potential hands\n",
    "                hand1_original = frame_vec_84[:FEATURES_PER_HAND]\n",
    "                hand2_original = frame_vec_84[FEATURES_PER_HAND:]\n",
    "\n",
    "                # Mirror each part (mirroring zeros is harmless)\n",
    "                hand1_mirrored = mirror_features(hand1_original.tolist()) # Convert np array slice to list\n",
    "                hand2_mirrored = mirror_features(hand2_original.tolist())\n",
    "\n",
    "                # Handle potential None from mirroring failure (though unlikely with zeros)\n",
    "                if hand1_mirrored is None: hand1_mirrored = np.zeros(FEATURES_PER_HAND, dtype=np.float32)\n",
    "                if hand2_mirrored is None: hand2_mirrored = np.zeros(FEATURES_PER_HAND, dtype=np.float32)\n",
    "\n",
    "                # Combine mirrored parts\n",
    "                mirrored_frame_vec_84 = np.concatenate([hand1_mirrored, hand2_mirrored]).astype(np.float32)\n",
    "                mirrored_sequence.append(mirrored_frame_vec_84)\n",
    "\n",
    "            # Add the complete mirrored sequence\n",
    "            all_sequences_data.append(mirrored_sequence)\n",
    "            all_sequences_labels.append(sign_class) # Same label for mirrored version\n",
    "\n",
    "        elif not valid_sequence:\n",
    "             skipped_sequences_count += 1\n",
    "        # else: sequence length was wrong (already handled)\n",
    "\n",
    "\n",
    "# --- Final Steps ---\n",
    "hands.close() # Release MediaPipe resources\n",
    "\n",
    "print(\"\\n\" + \"-\" * 30)\n",
    "print(\"Processing Summary:\")\n",
    "print(f\"  Total sequences processed (before mirroring): {processed_sequences_count}\")\n",
    "print(f\"  Total sequences skipped (frame errors/count mismatch): {skipped_sequences_count}\")\n",
    "print(f\"  Total samples generated (including mirrored): {len(all_sequences_data)}\")\n",
    "print(f\"  Total labels generated: {len(all_sequences_labels)}\")\n",
    "\n",
    "if not all_sequences_data:\n",
    "    print(\"\\nError: No valid sequences were processed. Cannot save dataset.\")\n",
    "else:\n",
    "    # Convert to NumPy arrays\n",
    "    # Ensure all sequences are numpy arrays of the correct shape\n",
    "    try:\n",
    "        data_array = np.array(all_sequences_data, dtype=np.float32)\n",
    "        label_array = np.array(all_sequences_labels)\n",
    "\n",
    "        print(f\"\\nFinal data array shape: {data_array.shape}\") # Should be (num_samples, SEQUENCE_LENGTH, TARGET_FEATURES_PER_FRAME)\n",
    "        print(f\"Final label array shape: {label_array.shape}\")\n",
    "\n",
    "        # Shuffle the data\n",
    "        indices = np.random.permutation(len(data_array))\n",
    "        shuffled_data = data_array[indices]\n",
    "        shuffled_labels = label_array[indices]\n",
    "\n",
    "        # Create output directory if needed\n",
    "        output_dir = os.path.dirname(OUTPUT_PICKLE_FILE)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        # Save the dataset\n",
    "        print(f\"\\nSaving shuffled dataset to: {OUTPUT_PICKLE_FILE}\")\n",
    "        try:\n",
    "            with open(OUTPUT_PICKLE_FILE, 'wb') as f:\n",
    "                # Saving as dictionary for clarity, converting arrays to lists for pickle compatibility if needed\n",
    "                # Using np.save might be more efficient for large arrays, but pickle is common\n",
    "                pickle.dump({'data': shuffled_data.tolist(), 'labels': shuffled_labels.tolist()}, f)\n",
    "            print(\"Dataset saved successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving pickle file: {e}\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nError creating final NumPy array. This might be due to inconsistent sequence lengths or feature vector sizes: {e}\")\n",
    "        print(\"Please check warnings during processing.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred during final processing: {e}\")\n",
    "\n",
    "print(\"\\nDataset creation script finished.\")\n",
    "# ```\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9d4086",
   "metadata": {},
   "source": [
    "Try Create DataSet with Z Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abca7272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746338170.724777 27857068 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Pro\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dataset Creation Configuration ---\n",
      "Data Source Directory: ./data_alphabet_sequences\n",
      "Output Pickle File: ./train_data_set/asl_sequences_dataset_sorted_1.pickle\n",
      "Target Sequence Length: 10\n",
      "Include Z Coordinate: True\n",
      "Features per Landmark: 3\n",
      "Features per Hand: 63\n",
      "Target Features per Frame (2 Hands): 126\n",
      "Classes to Process: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'Hello', 'My', 'Engineer', 'Name', 'Yes', 'No', 'Me']\n",
      "----------------------------------------\n",
      "\n",
      "Processing Class: A...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sequences for A:   0%|          | 0/10 [00:00<?, ?seq/s]W0000 00:00:1746338170.729659 28517192 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746338170.733465 28517192 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: B...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: C...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: D...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: E...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: F...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: G...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: H...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: I...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: J...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: K...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: L...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: M...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: N...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: O...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: P...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: Q...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: R...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: S...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: T...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: U...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: V...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: W...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: X...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: Y...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: Z...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: Hello...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: My...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: Engineer...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: Name...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: Yes...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: No...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Class: Me...\n",
      "  Found 10 sequence folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Processing Summary:\n",
      "  Total sequences processed (before mirroring): 330\n",
      "  Total sequences skipped: 0\n",
      "  Total samples generated (including mirrored): 660\n",
      "  Total labels generated: 660\n",
      "----------------------------------------\n",
      "\n",
      "Final data array shape: (660, 10, 126)\n",
      "Final label array shape: (660,)\n",
      "Data and labels shuffled.\n",
      "\n",
      "Saving shuffled dataset to: ./train_data_set/asl_sequences_dataset_sorted_1.pickle\n",
      "Dataset saved successfully.\n",
      "\n",
      "Dataset creation script finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm # For progress bar\n",
    "import traceback # For detailed error logging\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_DIR = './data_alphabet_sequences' # Directory where sequence folders are stored\n",
    "OUTPUT_PICKLE_FILE = './train_data_set/asl_sequences_dataset_3D.pickle' # Output file path\n",
    "SEQUENCE_LENGTH = 10          # Fixed sequence length as requested\n",
    "NUM_LANDMARKS = 21            # Number of landmarks per hand (MediaPipe default)\n",
    "USE_Z_COORDINATE = True      # Set to True to include Z coordinate (depth)\n",
    "\n",
    "# Calculate features based on configuration\n",
    "FEATURES_PER_LANDMARK = 3 if USE_Z_COORDINATE else 2\n",
    "FEATURES_PER_HAND = NUM_LANDMARKS * FEATURES_PER_LANDMARK # 63 if Z used, 42 otherwise\n",
    "TARGET_FEATURES_PER_FRAME = FEATURES_PER_HAND * 2         # Total features for two hands (126 or 84)\n",
    "\n",
    "# Define the classes you want to process\n",
    "# Make sure these match folder names in DATA_DIR\n",
    "classes_to_process = ['A','B','C','D','E','F','G','H','I','J','K','L','M',\n",
    "                      'N','O','P','Q','R','S','T','U','V','W','X','Y','Z',\n",
    "                      'Hello','My','Engineer','Name','Yes','No','Me']\n",
    "# --- MediaPipe Initialization ---\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,       # Process video frames\n",
    "    max_num_hands=2,               # Detect up to two hands\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "mp_drawing = mp.solutions.drawing_utils # For visualization (optional)\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def normalize_landmarks(landmarks, image_shape):\n",
    "    \"\"\"\n",
    "    Normalizes landmarks relative to the hand's bounding box.\n",
    "    Includes Z coordinate if USE_Z_COORDINATE is True.\n",
    "    Returns a list of features (42 or 63) or None if normalization fails.\n",
    "    \"\"\"\n",
    "    if not landmarks:\n",
    "        return None\n",
    "\n",
    "    # Extract coordinates into lists\n",
    "    x_coords_px = [lm.x * image_shape[1] for lm in landmarks.landmark] # Pixel coords\n",
    "    y_coords_px = [lm.y * image_shape[0] for lm in landmarks.landmark]\n",
    "    # Z coordinate from MediaPipe is relative depth to wrist, usually needs less normalization\n",
    "    z_coords = [lm.z for lm in landmarks.landmark]\n",
    "\n",
    "    if not x_coords_px or not y_coords_px: # Should not happen if landmarks exist, but check\n",
    "        return None\n",
    "\n",
    "    # Calculate bounding box\n",
    "    x_min, x_max = min(x_coords_px), max(x_coords_px)\n",
    "    y_min, y_max = min(y_coords_px), max(y_coords_px)\n",
    "\n",
    "    # Avoid division by zero for degenerate bounding boxes (e.g., hand at edge)\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    if width == 0 or height == 0:\n",
    "        # print(f\"Warning: Degenerate bounding box detected (width={width}, height={height}). Skipping normalization for this hand.\")\n",
    "        # Return zeros or None? Returning None indicates failure for this hand.\n",
    "        return None\n",
    "\n",
    "    # Normalize x, y relative to the bounding box\n",
    "    normalized_features = []\n",
    "    for i, lm in enumerate(landmarks.landmark):\n",
    "        norm_x = (x_coords_px[i] - x_min) / width\n",
    "        norm_y = (y_coords_px[i] - y_min) / height\n",
    "        normalized_features.extend([norm_x, norm_y])\n",
    "        if USE_Z_COORDINATE:\n",
    "            # Z is often used directly or normalized differently (e.g., scaling)\n",
    "            # Here, we'll just include it as is for simplicity.\n",
    "            # Consider scaling z_coords relative to wrist z if needed later.\n",
    "            normalized_features.append(z_coords[i])\n",
    "\n",
    "    # Final check on feature count\n",
    "    if len(normalized_features) != FEATURES_PER_HAND:\n",
    "        print(f\"Warning: Incorrect feature count after normalization: {len(normalized_features)}, expected {FEATURES_PER_HAND}.\")\n",
    "        return None\n",
    "\n",
    "    return normalized_features\n",
    "\n",
    "def mirror_features(features_hand):\n",
    "    \"\"\"\n",
    "    Mirrors a single hand's feature vector horizontally.\n",
    "    Handles both 2D (42 features) and 3D (63 features).\n",
    "    \"\"\"\n",
    "    if features_hand is None or len(features_hand) != FEATURES_PER_HAND:\n",
    "        # Return zeros of the correct dimension if input is invalid/padded\n",
    "        return np.zeros(FEATURES_PER_HAND, dtype=np.float32).tolist()\n",
    "\n",
    "    mirrored = []\n",
    "    step = FEATURES_PER_LANDMARK # 2 for XY, 3 for XYZ\n",
    "    for i in range(0, FEATURES_PER_HAND, step):\n",
    "        norm_x = features_hand[i]\n",
    "        mirrored_norm_x = 1.0 - norm_x # Flip normalized x\n",
    "        mirrored.append(mirrored_norm_x)\n",
    "        mirrored.append(features_hand[i+1]) # Keep y\n",
    "        if USE_Z_COORDINATE:\n",
    "            mirrored.append(features_hand[i+2]) # Keep z\n",
    "\n",
    "    return mirrored\n",
    "\n",
    "# --- Main Processing Logic ---\n",
    "\n",
    "all_sequences_data = []\n",
    "all_sequences_labels = []\n",
    "processed_sequences_count = 0\n",
    "skipped_sequences_count = 0\n",
    "skipped_sequences_details = {} # Store reasons for skipping\n",
    "\n",
    "print(\"--- Dataset Creation Configuration ---\")\n",
    "print(f\"Data Source Directory: {DATA_DIR}\")\n",
    "print(f\"Output Pickle File: {OUTPUT_PICKLE_FILE}\")\n",
    "print(f\"Target Sequence Length: {SEQUENCE_LENGTH}\")\n",
    "print(f\"Include Z Coordinate: {USE_Z_COORDINATE}\")\n",
    "print(f\"Features per Landmark: {FEATURES_PER_LANDMARK}\")\n",
    "print(f\"Features per Hand: {FEATURES_PER_HAND}\")\n",
    "print(f\"Target Features per Frame (2 Hands): {TARGET_FEATURES_PER_FRAME}\")\n",
    "print(f\"Classes to Process: {classes_to_process}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Iterate through specified class directories\n",
    "for sign_class in classes_to_process:\n",
    "    class_path = os.path.join(DATA_DIR, sign_class)\n",
    "    print(f\"\\nProcessing Class: {sign_class}...\")\n",
    "\n",
    "    if not os.path.isdir(class_path):\n",
    "        print(f\"  Warning: Directory not found for class '{sign_class}'. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Iterate through sequence folders (e.g., '000', '001', ...)\n",
    "    sequence_folders = sorted([f for f in os.listdir(class_path) if os.path.isdir(os.path.join(class_path, f)) and f.isdigit()])\n",
    "\n",
    "    if not sequence_folders:\n",
    "        print(f\"  No sequence folders found in {class_path}. Skipping class.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"  Found {len(sequence_folders)} sequence folders.\")\n",
    "\n",
    "    for seq_folder_name in tqdm(sequence_folders, desc=f\"  Sequences for {sign_class}\", unit=\"seq\", leave=False):\n",
    "        seq_path = os.path.join(class_path, seq_folder_name)\n",
    "        sequence_frame_features = [] # Store features for all frames in this sequence\n",
    "        sequence_skipped = False\n",
    "        skip_reason = \"\"\n",
    "\n",
    "        frame_files = sorted([f for f in os.listdir(seq_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n",
    "\n",
    "        # Ensure frames are processed in numeric order\n",
    "        try:\n",
    "            frame_files.sort(key=lambda x: int(os.path.splitext(x)[0]))\n",
    "        except ValueError:\n",
    "            print(f\"\\n  Warning: Non-numeric frame filenames found in {seq_path}. Skipping sequence.\")\n",
    "            sequence_skipped = True\n",
    "            skip_reason = \"Non-numeric filenames\"\n",
    "\n",
    "        if not sequence_skipped and len(frame_files) != SEQUENCE_LENGTH:\n",
    "             # print(f\"\\n  Warning: Sequence {seq_folder_name} in class {sign_class} has {len(frame_files)} frames, expected {SEQUENCE_LENGTH}. Skipping.\")\n",
    "             sequence_skipped = True\n",
    "             skip_reason = f\"Incorrect frame count ({len(frame_files)} vs {SEQUENCE_LENGTH})\"\n",
    "             # Continue processing frames below, but mark sequence as skipped\n",
    "\n",
    "        if sequence_skipped:\n",
    "            skipped_sequences_count += 1\n",
    "            if sign_class not in skipped_sequences_details: skipped_sequences_details[sign_class] = {}\n",
    "            if skip_reason not in skipped_sequences_details[sign_class]: skipped_sequences_details[sign_class][skip_reason] = 0\n",
    "            skipped_sequences_details[sign_class][skip_reason] += 1\n",
    "            continue # Skip to the next sequence folder\n",
    "\n",
    "\n",
    "        # Process frames if count is correct\n",
    "        valid_sequence_frames = True\n",
    "        for frame_filename in frame_files:\n",
    "            frame_path = os.path.join(seq_path, frame_filename)\n",
    "            frame = cv2.imread(frame_path)\n",
    "\n",
    "            if frame is None:\n",
    "                print(f\"\\n  Warning: Failed to read frame {frame_path}. Skipping sequence {seq_folder_name}.\")\n",
    "                valid_sequence_frames = False\n",
    "                skip_reason = f\"Failed to read frame {frame_filename}\"\n",
    "                break # Skip rest of the frames in this sequence\n",
    "\n",
    "            # Process frame with MediaPipe\n",
    "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image_rgb.flags.writeable = False # Optimize\n",
    "            results = hands.process(image_rgb)\n",
    "            image_rgb.flags.writeable = True\n",
    "\n",
    "            # Initialize frame features with zeros (padding)\n",
    "            frame_features = np.zeros(TARGET_FEATURES_PER_FRAME, dtype=np.float32)\n",
    "            detected_hands_data = [] # Store tuples of (wrist_x, normalized_features)\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                # Normalize landmarks for each detected hand\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    norm_features = normalize_landmarks(hand_landmarks, frame.shape)\n",
    "                    if norm_features:\n",
    "                        # Get wrist x-coordinate (landmark 0, x is the first feature) for sorting\n",
    "                        wrist_x = hand_landmarks.landmark[0].x\n",
    "                        detected_hands_data.append((wrist_x, norm_features))\n",
    "\n",
    "                # Sort hands by horizontal position (leftmost first)\n",
    "                detected_hands_data.sort(key=lambda item: item[0]) # Sort based on wrist_x\n",
    "\n",
    "                # Assign features based on sorted order (up to 2 hands)\n",
    "                num_hands_to_assign = min(len(detected_hands_data), 2)\n",
    "                for i in range(num_hands_to_assign):\n",
    "                    hand_features = detected_hands_data[i][1] # Get the normalized features\n",
    "                    start_index = i * FEATURES_PER_HAND\n",
    "                    end_index = start_index + FEATURES_PER_HAND\n",
    "                    frame_features[start_index:end_index] = hand_features\n",
    "\n",
    "            # Append the (potentially padded) features for this frame\n",
    "            sequence_frame_features.append(frame_features)\n",
    "\n",
    "        # After processing all frames for the sequence\n",
    "        if not valid_sequence_frames:\n",
    "             skipped_sequences_count += 1\n",
    "             if sign_class not in skipped_sequences_details: skipped_sequences_details[sign_class] = {}\n",
    "             if skip_reason not in skipped_sequences_details[sign_class]: skipped_sequences_details[sign_class][skip_reason] = 0\n",
    "             skipped_sequences_details[sign_class][skip_reason] += 1\n",
    "             continue # Skip this sequence\n",
    "\n",
    "        # If we reached here, the sequence has the correct length and all frames were read\n",
    "        if len(sequence_frame_features) == SEQUENCE_LENGTH:\n",
    "            processed_sequences_count += 1\n",
    "\n",
    "            # 1. Add the original sequence\n",
    "            all_sequences_data.append(sequence_frame_features)\n",
    "            all_sequences_labels.append(sign_class)\n",
    "\n",
    "            # 2. Create and add the mirrored sequence\n",
    "            mirrored_sequence = []\n",
    "            for frame_vec in sequence_frame_features:\n",
    "                # Separate the features into two potential hands\n",
    "                # frame_vec is already a numpy array here\n",
    "                hand1_original = frame_vec[:FEATURES_PER_HAND].tolist() # Convert slice to list for mirror func\n",
    "                hand2_original = frame_vec[FEATURES_PER_HAND:].tolist()\n",
    "\n",
    "                # Mirror each part\n",
    "                hand1_mirrored = mirror_features(hand1_original)\n",
    "                hand2_mirrored = mirror_features(hand2_original)\n",
    "\n",
    "                # Combine mirrored parts. IMPORTANT: Maintain the sorted order logic.\n",
    "                # The hand that was originally on the left (hand1) becomes the mirrored right hand.\n",
    "                # The hand that was originally on the right (hand2) becomes the mirrored left hand.\n",
    "                # So, the mirrored features for hand2 should come first in the mirrored vector.\n",
    "                mirrored_frame_vec = np.concatenate([hand2_mirrored, hand1_mirrored]).astype(np.float32)\n",
    "                mirrored_sequence.append(mirrored_frame_vec)\n",
    "\n",
    "            # Add the complete mirrored sequence\n",
    "            all_sequences_data.append(mirrored_sequence)\n",
    "            all_sequences_labels.append(sign_class) # Same label\n",
    "\n",
    "        else:\n",
    "            # This case should ideally not be reached due to checks above, but as a safeguard:\n",
    "            print(f\"\\n  Internal Warning: Sequence {seq_folder_name} ({sign_class}) ended with {len(sequence_frame_features)} frames processed, expected {SEQUENCE_LENGTH}. Skipping.\")\n",
    "            skipped_sequences_count += 1\n",
    "            skip_reason = \"Post-processing frame count mismatch\"\n",
    "            if sign_class not in skipped_sequences_details: skipped_sequences_details[sign_class] = {}\n",
    "            if skip_reason not in skipped_sequences_details[sign_class]: skipped_sequences_details[sign_class][skip_reason] = 0\n",
    "            skipped_sequences_details[sign_class][skip_reason] += 1\n",
    "\n",
    "\n",
    "# --- Final Steps ---\n",
    "hands.close() # Release MediaPipe resources\n",
    "\n",
    "print(\"\\n\" + \"-\" * 40)\n",
    "print(\"Processing Summary:\")\n",
    "print(f\"  Total sequences processed (before mirroring): {processed_sequences_count}\")\n",
    "print(f\"  Total sequences skipped: {skipped_sequences_count}\")\n",
    "if skipped_sequences_count > 0:\n",
    "    print(\"  Skipped sequence details (Class -> Reason -> Count):\")\n",
    "    for class_name, reasons in skipped_sequences_details.items():\n",
    "        print(f\"    {class_name}:\")\n",
    "        for reason, count in reasons.items():\n",
    "            print(f\"      - {reason}: {count}\")\n",
    "print(f\"  Total samples generated (including mirrored): {len(all_sequences_data)}\")\n",
    "print(f\"  Total labels generated: {len(all_sequences_labels)}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if not all_sequences_data:\n",
    "    print(\"\\nError: No valid sequences were processed. Cannot save dataset.\")\n",
    "else:\n",
    "    # Convert to NumPy arrays\n",
    "    try:\n",
    "        data_array = np.array(all_sequences_data, dtype=np.float32)\n",
    "        label_array = np.array(all_sequences_labels)\n",
    "\n",
    "        print(f\"\\nFinal data array shape: {data_array.shape}\") # Should be (num_samples, SEQUENCE_LENGTH, TARGET_FEATURES_PER_FRAME)\n",
    "        print(f\"Final label array shape: {label_array.shape}\")\n",
    "\n",
    "        # Ensure the shape is as expected\n",
    "        expected_shape = (len(all_sequences_data), SEQUENCE_LENGTH, TARGET_FEATURES_PER_FRAME)\n",
    "        if data_array.shape != expected_shape:\n",
    "             raise ValueError(f\"Final data array shape mismatch! Expected {expected_shape}, got {data_array.shape}. Check for inconsistent frame feature vectors.\")\n",
    "\n",
    "\n",
    "        # Shuffle the data and labels together\n",
    "        indices = np.random.permutation(len(data_array))\n",
    "        shuffled_data = data_array[indices]\n",
    "        shuffled_labels = label_array[indices]\n",
    "        print(\"Data and labels shuffled.\")\n",
    "\n",
    "        # Create output directory if needed\n",
    "        output_dir = os.path.dirname(OUTPUT_PICKLE_FILE)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            print(f\"Created output directory: {output_dir}\")\n",
    "\n",
    "        # Save the dataset as a dictionary in a pickle file\n",
    "        dataset = {'data': shuffled_data, 'labels': shuffled_labels}\n",
    "        print(f\"\\nSaving shuffled dataset to: {OUTPUT_PICKLE_FILE}\")\n",
    "        try:\n",
    "            with open(OUTPUT_PICKLE_FILE, 'wb') as f:\n",
    "                pickle.dump(dataset, f)\n",
    "            print(\"Dataset saved successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving pickle file: {e}\")\n",
    "            traceback.print_exc() # Print detailed traceback\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nError creating final NumPy array: {e}\")\n",
    "        print(\"This often happens if some sequences didn't produce vectors of the exact expected size.\")\n",
    "        print(\"Please check warnings during processing and the shapes of individual sequence_frame_features lists.\")\n",
    "        traceback.print_exc()\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred during final processing: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"\\nDataset creation script finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212d9b67",
   "metadata": {},
   "source": [
    "<h2>3. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97702bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Apple Silicon GPU)\n",
      "Loading data from: ./train_data_set/asl_sequences_dataset.pickle\n",
      "Loaded 660 samples.\n",
      "Data array shape: (660, 10, 84)\n",
      "Number of classes: 33\n",
      "Label map created: {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'Engineer': 5, 'F': 6, 'G': 7, 'H': 8, 'Hello': 9, 'I': 10, 'J': 11, 'K': 12, 'L': 13, 'M': 14, 'Me': 15, 'My': 16, 'N': 17, 'Name': 18, 'No': 19, 'O': 20, 'P': 21, 'Q': 22, 'R': 23, 'S': 24, 'T': 25, 'U': 26, 'V': 27, 'W': 28, 'X': 29, 'Y': 30, 'Yes': 31, 'Z': 32}\n",
      "Train samples: 528, Test samples: 132\n",
      "\n",
      "Model Architecture:\n",
      "HandGestureLSTM(\n",
      "  (lstm): LSTM(84, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=33, bias=True)\n",
      ")\n",
      "\n",
      "Starting Training...\n",
      "Epoch 1/100 | Train Loss: 3.4953 | Train Acc: 0.0417 | Val Loss: 3.4712 | Val Acc: 0.0530 | Duration: 0.27s\n",
      "  Validation accuracy improved. Saved model to ./models/best_lstm_model_sequences.pth\n",
      "Epoch 2/100 | Train Loss: 3.4150 | Train Acc: 0.0947 | Val Loss: 3.2685 | Val Acc: 0.1136 | Duration: 0.08s\n",
      "  Validation accuracy improved. Saved model to ./models/best_lstm_model_sequences.pth\n",
      "Epoch 3/100 | Train Loss: 3.0509 | Train Acc: 0.1383 | Val Loss: 2.7204 | Val Acc: 0.1818 | Duration: 0.08s\n",
      "  Validation accuracy improved. Saved model to ./models/best_lstm_model_sequences.pth\n",
      "Epoch 4/100 | Train Loss: 2.5474 | Train Acc: 0.2386 | Val Loss: 2.2613 | Val Acc: 0.3409 | Duration: 0.08s\n",
      "  Validation accuracy improved. Saved model to ./models/best_lstm_model_sequences.pth\n",
      "Epoch 5/100 | Train Loss: 2.0587 | Train Acc: 0.3939 | Val Loss: 1.7562 | Val Acc: 0.4848 | Duration: 0.09s\n",
      "  Validation accuracy improved. Saved model to ./models/best_lstm_model_sequences.pth\n",
      "Epoch 6/100 | Train Loss: 1.7078 | Train Acc: 0.4545 | Val Loss: 1.3958 | Val Acc: 0.6818 | Duration: 0.09s\n",
      "  Validation accuracy improved. Saved model to ./models/best_lstm_model_sequences.pth\n",
      "Epoch 7/100 | Train Loss: 1.3628 | Train Acc: 0.5758 | Val Loss: 1.1407 | Val Acc: 0.7348 | Duration: 0.08s\n",
      "  Validation accuracy improved. Saved model to ./models/best_lstm_model_sequences.pth\n",
      "Epoch 8/100 | Train Loss: 1.2008 | Train Acc: 0.6250 | Val Loss: 1.1145 | Val Acc: 0.6364 | Duration: 0.11s\n",
      "  Validation accuracy did not improve. Counter: 1/15\n",
      "Epoch 9/100 | Train Loss: 1.0496 | Train Acc: 0.6723 | Val Loss: 0.9728 | Val Acc: 0.6970 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 2/15\n",
      "Epoch 10/100 | Train Loss: 1.0261 | Train Acc: 0.6705 | Val Loss: 0.7907 | Val Acc: 0.8258 | Duration: 0.08s\n",
      "  Validation accuracy improved. Saved model to ./models/best_lstm_model_sequences.pth\n",
      "Epoch 11/100 | Train Loss: 0.8894 | Train Acc: 0.7178 | Val Loss: 0.7445 | Val Acc: 0.7652 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 1/15\n",
      "Epoch 12/100 | Train Loss: 0.7643 | Train Acc: 0.7614 | Val Loss: 0.7419 | Val Acc: 0.7955 | Duration: 0.10s\n",
      "  Validation accuracy did not improve. Counter: 2/15\n",
      "Epoch 13/100 | Train Loss: 0.6991 | Train Acc: 0.7784 | Val Loss: 0.5818 | Val Acc: 0.8561 | Duration: 0.10s\n",
      "  Validation accuracy improved. Saved model to ./models/best_lstm_model_sequences.pth\n",
      "Epoch 14/100 | Train Loss: 0.5965 | Train Acc: 0.8201 | Val Loss: 0.4776 | Val Acc: 0.8939 | Duration: 0.10s\n",
      "  Validation accuracy improved. Saved model to ./models/best_lstm_model_sequences.pth\n",
      "Epoch 15/100 | Train Loss: 0.5583 | Train Acc: 0.8295 | Val Loss: 0.4758 | Val Acc: 0.8788 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 1/15\n",
      "Epoch 16/100 | Train Loss: 0.4956 | Train Acc: 0.8409 | Val Loss: 0.5337 | Val Acc: 0.8182 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 2/15\n",
      "Epoch 17/100 | Train Loss: 0.5251 | Train Acc: 0.8125 | Val Loss: 0.4494 | Val Acc: 0.8333 | Duration: 0.10s\n",
      "  Validation accuracy did not improve. Counter: 3/15\n",
      "Epoch 18/100 | Train Loss: 0.4380 | Train Acc: 0.8674 | Val Loss: 0.4207 | Val Acc: 0.8864 | Duration: 0.10s\n",
      "  Validation accuracy did not improve. Counter: 4/15\n",
      "Epoch 19/100 | Train Loss: 0.4649 | Train Acc: 0.8485 | Val Loss: 0.3824 | Val Acc: 0.8864 | Duration: 0.10s\n",
      "  Validation accuracy did not improve. Counter: 5/15\n",
      "Epoch 20/100 | Train Loss: 0.4281 | Train Acc: 0.8712 | Val Loss: 0.3764 | Val Acc: 0.8788 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 6/15\n",
      "Epoch 21/100 | Train Loss: 0.4136 | Train Acc: 0.8523 | Val Loss: 0.3867 | Val Acc: 0.8485 | Duration: 0.07s\n",
      "  Validation accuracy did not improve. Counter: 7/15\n",
      "Epoch 22/100 | Train Loss: 0.3807 | Train Acc: 0.8712 | Val Loss: 0.4099 | Val Acc: 0.8788 | Duration: 0.08s\n",
      "  Validation accuracy did not improve. Counter: 8/15\n",
      "Epoch 23/100 | Train Loss: 0.3357 | Train Acc: 0.9034 | Val Loss: 0.2683 | Val Acc: 0.9318 | Duration: 0.10s\n",
      "  Validation accuracy improved. Saved model to ./models/best_lstm_model_sequences.pth\n",
      "Epoch 24/100 | Train Loss: 0.3540 | Train Acc: 0.8902 | Val Loss: 0.3848 | Val Acc: 0.8561 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 1/15\n",
      "Epoch 25/100 | Train Loss: 0.4243 | Train Acc: 0.8655 | Val Loss: 0.3551 | Val Acc: 0.8712 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 2/15\n",
      "Epoch 26/100 | Train Loss: 0.3645 | Train Acc: 0.8845 | Val Loss: 0.2930 | Val Acc: 0.8939 | Duration: 0.08s\n",
      "  Validation accuracy did not improve. Counter: 3/15\n",
      "Epoch 27/100 | Train Loss: 0.4423 | Train Acc: 0.8542 | Val Loss: 0.3876 | Val Acc: 0.8864 | Duration: 0.10s\n",
      "  Validation accuracy did not improve. Counter: 4/15\n",
      "Epoch 28/100 | Train Loss: 0.3379 | Train Acc: 0.8902 | Val Loss: 0.4070 | Val Acc: 0.8485 | Duration: 0.08s\n",
      "  Validation accuracy did not improve. Counter: 5/15\n",
      "Epoch 29/100 | Train Loss: 0.3104 | Train Acc: 0.9148 | Val Loss: 0.2266 | Val Acc: 0.9545 | Duration: 0.07s\n",
      "  Validation accuracy improved. Saved model to ./models/best_lstm_model_sequences.pth\n",
      "Epoch 30/100 | Train Loss: 0.2224 | Train Acc: 0.9508 | Val Loss: 0.2225 | Val Acc: 0.9394 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 1/15\n",
      "Epoch 31/100 | Train Loss: 0.2231 | Train Acc: 0.9470 | Val Loss: 0.2384 | Val Acc: 0.9167 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 2/15\n",
      "Epoch 32/100 | Train Loss: 0.1961 | Train Acc: 0.9337 | Val Loss: 0.2738 | Val Acc: 0.8864 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 3/15\n",
      "Epoch 33/100 | Train Loss: 0.1908 | Train Acc: 0.9545 | Val Loss: 0.1556 | Val Acc: 0.9545 | Duration: 0.10s\n",
      "  Validation accuracy did not improve. Counter: 4/15\n",
      "Epoch 34/100 | Train Loss: 0.1780 | Train Acc: 0.9508 | Val Loss: 0.1862 | Val Acc: 0.9545 | Duration: 0.10s\n",
      "  Validation accuracy did not improve. Counter: 5/15\n",
      "Epoch 35/100 | Train Loss: 0.2466 | Train Acc: 0.9167 | Val Loss: 0.2944 | Val Acc: 0.8939 | Duration: 0.10s\n",
      "  Validation accuracy did not improve. Counter: 6/15\n",
      "Epoch 36/100 | Train Loss: 0.2435 | Train Acc: 0.9375 | Val Loss: 0.3036 | Val Acc: 0.9091 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 7/15\n",
      "Epoch 37/100 | Train Loss: 0.2939 | Train Acc: 0.8920 | Val Loss: 0.4162 | Val Acc: 0.8561 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 8/15\n",
      "Epoch 38/100 | Train Loss: 0.4309 | Train Acc: 0.8561 | Val Loss: 0.4021 | Val Acc: 0.8712 | Duration: 0.08s\n",
      "  Validation accuracy did not improve. Counter: 9/15\n",
      "Epoch 39/100 | Train Loss: 0.2597 | Train Acc: 0.9280 | Val Loss: 0.1932 | Val Acc: 0.9470 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 10/15\n",
      "Epoch 40/100 | Train Loss: 0.2186 | Train Acc: 0.9280 | Val Loss: 0.1979 | Val Acc: 0.9394 | Duration: 0.08s\n",
      "  Validation accuracy did not improve. Counter: 11/15\n",
      "Epoch 41/100 | Train Loss: 0.1585 | Train Acc: 0.9640 | Val Loss: 0.1826 | Val Acc: 0.9242 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 12/15\n",
      "Epoch 42/100 | Train Loss: 0.1649 | Train Acc: 0.9545 | Val Loss: 0.1318 | Val Acc: 0.9545 | Duration: 0.10s\n",
      "  Validation accuracy did not improve. Counter: 13/15\n",
      "Epoch 43/100 | Train Loss: 0.1236 | Train Acc: 0.9697 | Val Loss: 0.1321 | Val Acc: 0.9621 | Duration: 0.08s\n",
      "  Validation accuracy improved. Saved model to ./models/best_lstm_model_sequences.pth\n",
      "Epoch 44/100 | Train Loss: 0.1711 | Train Acc: 0.9527 | Val Loss: 0.2254 | Val Acc: 0.9242 | Duration: 0.07s\n",
      "  Validation accuracy did not improve. Counter: 1/15\n",
      "Epoch 45/100 | Train Loss: 0.2041 | Train Acc: 0.9527 | Val Loss: 0.2447 | Val Acc: 0.9394 | Duration: 0.07s\n",
      "  Validation accuracy did not improve. Counter: 2/15\n",
      "Epoch 46/100 | Train Loss: 0.1337 | Train Acc: 0.9640 | Val Loss: 0.1484 | Val Acc: 0.9621 | Duration: 0.07s\n",
      "  Validation accuracy did not improve. Counter: 3/15\n",
      "Epoch 47/100 | Train Loss: 0.0931 | Train Acc: 0.9830 | Val Loss: 0.0902 | Val Acc: 0.9697 | Duration: 0.09s\n",
      "  Validation accuracy improved. Saved model to ./models/best_lstm_model_sequences.pth\n",
      "Epoch 48/100 | Train Loss: 0.1136 | Train Acc: 0.9659 | Val Loss: 0.3515 | Val Acc: 0.8939 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 1/15\n",
      "Epoch 49/100 | Train Loss: 0.1060 | Train Acc: 0.9792 | Val Loss: 0.1818 | Val Acc: 0.9394 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 2/15\n",
      "Epoch 50/100 | Train Loss: 0.1574 | Train Acc: 0.9545 | Val Loss: 0.1287 | Val Acc: 0.9621 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 3/15\n",
      "Epoch 51/100 | Train Loss: 0.1484 | Train Acc: 0.9545 | Val Loss: 0.1519 | Val Acc: 0.9545 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 4/15\n",
      "Epoch 52/100 | Train Loss: 0.1993 | Train Acc: 0.9394 | Val Loss: 0.1882 | Val Acc: 0.9470 | Duration: 0.11s\n",
      "  Validation accuracy did not improve. Counter: 5/15\n",
      "Epoch 53/100 | Train Loss: 0.1685 | Train Acc: 0.9508 | Val Loss: 0.2525 | Val Acc: 0.9091 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 6/15\n",
      "Epoch 54/100 | Train Loss: 0.2108 | Train Acc: 0.9356 | Val Loss: 0.2623 | Val Acc: 0.9015 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 7/15\n",
      "Epoch 55/100 | Train Loss: 0.1961 | Train Acc: 0.9432 | Val Loss: 0.1994 | Val Acc: 0.9167 | Duration: 0.11s\n",
      "  Validation accuracy did not improve. Counter: 8/15\n",
      "Epoch 56/100 | Train Loss: 0.1506 | Train Acc: 0.9564 | Val Loss: 0.1387 | Val Acc: 0.9697 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 9/15\n",
      "Epoch 57/100 | Train Loss: 0.0966 | Train Acc: 0.9811 | Val Loss: 0.1081 | Val Acc: 0.9697 | Duration: 0.08s\n",
      "  Validation accuracy did not improve. Counter: 10/15\n",
      "Epoch 58/100 | Train Loss: 0.0629 | Train Acc: 0.9905 | Val Loss: 0.1056 | Val Acc: 0.9697 | Duration: 0.08s\n",
      "  Validation accuracy did not improve. Counter: 11/15\n",
      "Epoch 59/100 | Train Loss: 0.0764 | Train Acc: 0.9867 | Val Loss: 0.1404 | Val Acc: 0.9621 | Duration: 0.09s\n",
      "  Validation accuracy did not improve. Counter: 12/15\n",
      "Epoch 60/100 | Train Loss: 0.2176 | Train Acc: 0.9375 | Val Loss: 0.1675 | Val Acc: 0.9470 | Duration: 0.10s\n",
      "  Validation accuracy did not improve. Counter: 13/15\n",
      "Epoch 61/100 | Train Loss: 0.2246 | Train Acc: 0.9337 | Val Loss: 0.3419 | Val Acc: 0.9015 | Duration: 0.11s\n",
      "  Validation accuracy did not improve. Counter: 14/15\n",
      "Epoch 62/100 | Train Loss: 0.2947 | Train Acc: 0.9015 | Val Loss: 0.1794 | Val Acc: 0.9242 | Duration: 0.10s\n",
      "  Validation accuracy did not improve. Counter: 15/15\n",
      "  Early stopping triggered at epoch 62. Best Val Acc: 0.9697\n",
      "\n",
      "Training finished in 5.79 seconds.\n",
      "\n",
      "Loading best model from ./models/best_lstm_model_sequences.pth for final evaluation...\n",
      "Final Test Accuracy (Best Model): 0.9697\n",
      "Final Test Loss (Best Model): 0.0902\n",
      "\n",
      "Saving training history plot to ./models/training_history_lstm.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving label mapping to ./models/label_map_sequences.pickle\n",
      "Label mapping saved.\n",
      "\n",
      "Model training script finished.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_PICKLE_FILE = './train_data_set/asl_sequences_dataset.pickle'\n",
    "MODEL_SAVE_DIR = './models'\n",
    "BEST_MODEL_PATH = os.path.join(MODEL_SAVE_DIR, 'best_lstm_model_sequences.pth')\n",
    "LABEL_MAP_PATH = os.path.join(MODEL_SAVE_DIR, 'label_map_sequences.pickle')\n",
    "HISTORY_PLOT_PATH = os.path.join(MODEL_SAVE_DIR, 'training_history_lstm.png')\n",
    "\n",
    "# Ensure model save directory exists\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# --- Device Setup (Enable GPU on Mac if available) ---\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Apple Silicon GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# --- Load Data ---\n",
    "print(f\"Loading data from: {DATA_PICKLE_FILE}\")\n",
    "try:\n",
    "    with open(DATA_PICKLE_FILE, 'rb') as f:\n",
    "        data_dict = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file not found at {DATA_PICKLE_FILE}. Please run the dataset creation script first.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Extract data and labels\n",
    "# Data should be list of sequences, each sequence is list of feature vectors\n",
    "data = data_dict['data']\n",
    "labels = np.asarray(data_dict['labels'])\n",
    "\n",
    "print(f\"Loaded {len(data)} samples.\")\n",
    "if not data:\n",
    "    print(\"Error: No data loaded. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# --- Data Preparation ---\n",
    "# Convert data to numpy array (N, Sequence Length, Features)\n",
    "try:\n",
    "    # Assuming all sequences have the same length and feature dim from the creation script\n",
    "    data_array = np.array(data, dtype=np.float32)\n",
    "    print(f\"Data array shape: {data_array.shape}\") # Should be (num_samples, 30, 84)\n",
    "except ValueError as e:\n",
    "    print(f\"Error converting data to NumPy array. Ensure all sequences have the same length (30) and feature dim (84): {e}\")\n",
    "    # Optional: Add padding/truncating here if lengths vary, but the creation script should handle this.\n",
    "    exit()\n",
    "\n",
    "# Convert labels to numeric\n",
    "unique_labels = np.unique(labels)\n",
    "label_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "numeric_labels = np.array([label_map[label] for label in labels])\n",
    "reverse_label_map = {i: label for label, i in label_map.items()}\n",
    "num_classes = len(unique_labels)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Label map created: {label_map}\")\n",
    "\n",
    "# Split data (Train/Validation/Test) - Using 80% train, 20% test for simplicity now\n",
    "# For more robust evaluation, consider a separate validation set (e.g., 70/15/15 split)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data_array, numeric_labels, test_size=0.2, shuffle=True, stratify=numeric_labels, random_state=42\n",
    ")\n",
    "print(f\"Train samples: {len(x_train)}, Test samples: {len(x_test)}\")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_train_tensor = torch.FloatTensor(x_train)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "x_test_tensor = torch.FloatTensor(x_test)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "batch_size = 32 # Adjust as needed based on GPU memory\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# --- Define LSTM Model ---\n",
    "class HandGestureLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_prob=0.5):\n",
    "        super(HandGestureLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # batch_first=True means input tensor shape is (batch, seq_len, features)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
    "                            batch_first=True, dropout=dropout_prob if num_layers > 1 else 0)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state and cell state with zeros\n",
    "        # Shape: (num_layers, batch_size, hidden_size)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # We need to detach hidden states to prevent gradient flow back further than intended\n",
    "        # if they were carried over from previous batches (not applicable here as we re-initialize)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0.detach(), c0.detach())) # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.dropout(out[:, -1, :]) # Get output of the last time step\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# --- Model Initialization ---\n",
    "input_size = data_array.shape[2] # Should be 84\n",
    "hidden_size = 128 # Can be tuned\n",
    "num_layers = 2    # Can be tuned (e.g., 1 or 2 layers)\n",
    "dropout_prob = 0.5 # Can be tuned\n",
    "\n",
    "model = HandGestureLSTM(input_size, hidden_size, num_layers, num_classes, dropout_prob).to(device)\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Learning rate can be tuned\n",
    "\n",
    "# --- Training and Evaluation Functions ---\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train() # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += targets.size(0)\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate_epoch(model, test_loader, criterion, device):\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.inference_mode(): # Use inference_mode for efficiency\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += targets.size(0)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# --- Training Loop ---\n",
    "epochs = 100 # Adjust as needed\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "best_val_acc = 0.0\n",
    "patience = 15 # Number of epochs to wait for improvement before stopping\n",
    "counter = 0\n",
    "\n",
    "print(\"\\nStarting Training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate_epoch(model, test_loader, criterion, device)\n",
    "\n",
    "    epoch_duration = time.time() - epoch_start_time\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs} | '\n",
    "          f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | '\n",
    "          f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | '\n",
    "          f'Duration: {epoch_duration:.2f}s')\n",
    "\n",
    "    # Early stopping and saving best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        counter = 0\n",
    "        # Save best model state dictionary\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        print(f'  Validation accuracy improved. Saved model to {BEST_MODEL_PATH}')\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f'  Validation accuracy did not improve. Counter: {counter}/{patience}')\n",
    "        if counter >= patience:\n",
    "            print(f'  Early stopping triggered at epoch {epoch+1}. Best Val Acc: {best_val_acc:.4f}')\n",
    "            break\n",
    "\n",
    "training_duration = time.time() - start_time\n",
    "print(f\"\\nTraining finished in {training_duration:.2f} seconds.\")\n",
    "\n",
    "# --- Final Evaluation ---\n",
    "print(f\"\\nLoading best model from {BEST_MODEL_PATH} for final evaluation...\")\n",
    "try:\n",
    "    # Load the best performing model state\n",
    "    model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=device)) # Ensure loading to correct device\n",
    "    model.to(device) # Redundant if already on device, but safe\n",
    "\n",
    "    final_test_loss, final_test_acc = evaluate_epoch(model, test_loader, criterion, device)\n",
    "    print(f'Final Test Accuracy (Best Model): {final_test_acc:.4f}')\n",
    "    print(f'Final Test Loss (Best Model): {final_test_loss:.4f}')\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Best model file not found at {BEST_MODEL_PATH}. Cannot perform final evaluation.\")\n",
    "except Exception as e:\n",
    "     print(f\"Error loading best model or evaluating: {e}\")\n",
    "\n",
    "\n",
    "# --- Plot Training History ---\n",
    "print(f\"\\nSaving training history plot to {HISTORY_PLOT_PATH}\")\n",
    "try:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_accs, label='Train Accuracy')\n",
    "    plt.plot(val_accs, label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show() # Uncomment to display plot immediately if running interactively\n",
    "except Exception as e:\n",
    "    print(f\"Error generating or saving plot: {e}\")\n",
    "\n",
    "\n",
    "# --- Save Label Mapping ---\n",
    "print(f\"\\nSaving label mapping to {LABEL_MAP_PATH}\")\n",
    "try:\n",
    "    with open(LABEL_MAP_PATH, 'wb') as f:\n",
    "        pickle.dump({'label_map': label_map, 'reverse_label_map': reverse_label_map}, f)\n",
    "    print(\"Label mapping saved.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving label map: {e}\")\n",
    "\n",
    "print(\"\\nModel training script finished.\")\n",
    "# ```\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b1c076",
   "metadata": {},
   "source": [
    "Try use Z dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf515d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Apple Silicon GPU)\n",
      "Loading data from: ./train_data_set/asl_sequences_dataset_sorted_1.pickle\n",
      "Loaded 660 samples.\n",
      "Data array shape: (660, 10, 126)\n",
      "Number of classes: 33\n",
      "Class distribution:\n",
      "  - A: 20\n",
      "  - B: 20\n",
      "  - C: 20\n",
      "  - D: 20\n",
      "  - E: 20\n",
      "  - Engineer: 20\n",
      "  - F: 20\n",
      "  - G: 20\n",
      "  - H: 20\n",
      "  - Hello: 20\n",
      "  - I: 20\n",
      "  - J: 20\n",
      "  - K: 20\n",
      "  - L: 20\n",
      "  - M: 20\n",
      "  - Me: 20\n",
      "  - My: 20\n",
      "  - N: 20\n",
      "  - Name: 20\n",
      "  - No: 20\n",
      "  - O: 20\n",
      "  - P: 20\n",
      "  - Q: 20\n",
      "  - R: 20\n",
      "  - S: 20\n",
      "  - T: 20\n",
      "  - U: 20\n",
      "  - V: 20\n",
      "  - W: 20\n",
      "  - X: 20\n",
      "  - Y: 20\n",
      "  - Yes: 20\n",
      "  - Z: 20\n",
      "Train samples: 528, Validation samples: 132\n",
      "\n",
      "Model Architecture:\n",
      "HandGestureLSTM(\n",
      "  (lstm): LSTM(126, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=33, bias=True)\n",
      ")\n",
      "Input size: 126\n",
      "\n",
      "--- Starting Training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangnamtran/Desktop/Code/AI/ASL_Classification/venv311/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train Loss: 3.4988 | Train Acc: 0.0417 | Val Loss: 3.4677 | Val Acc: 0.0985 | Duration: 2.10s\n",
      "  Validation accuracy improved to 0.0985. Saved model to ./models/best_lstm_model_sequences_sorted_1.pth\n",
      "Epoch 2/100 | Train Loss: 3.4046 | Train Acc: 0.0814 | Val Loss: 3.2725 | Val Acc: 0.1515 | Duration: 1.76s\n",
      "  Validation accuracy improved to 0.1515. Saved model to ./models/best_lstm_model_sequences_sorted_1.pth\n",
      "Epoch 3/100 | Train Loss: 3.0515 | Train Acc: 0.1648 | Val Loss: 2.7048 | Val Acc: 0.1818 | Duration: 1.73s\n",
      "  Validation accuracy improved to 0.1818. Saved model to ./models/best_lstm_model_sequences_sorted_1.pth\n",
      "Epoch 4/100 | Train Loss: 2.4508 | Train Acc: 0.2879 | Val Loss: 2.2544 | Val Acc: 0.3485 | Duration: 1.83s\n",
      "  Validation accuracy improved to 0.3485. Saved model to ./models/best_lstm_model_sequences_sorted_1.pth\n",
      "Epoch 5/100 | Train Loss: 2.0223 | Train Acc: 0.3750 | Val Loss: 1.7121 | Val Acc: 0.4697 | Duration: 1.76s\n",
      "  Validation accuracy improved to 0.4697. Saved model to ./models/best_lstm_model_sequences_sorted_1.pth\n",
      "Epoch 6/100 | Train Loss: 1.6517 | Train Acc: 0.4697 | Val Loss: 1.4644 | Val Acc: 0.5530 | Duration: 1.75s\n",
      "  Validation accuracy improved to 0.5530. Saved model to ./models/best_lstm_model_sequences_sorted_1.pth\n",
      "Epoch 7/100 | Train Loss: 1.4277 | Train Acc: 0.5322 | Val Loss: 1.3702 | Val Acc: 0.4545 | Duration: 1.72s\n",
      "Epoch 8/100 | Train Loss: 1.2456 | Train Acc: 0.5871 | Val Loss: 1.0626 | Val Acc: 0.6894 | Duration: 1.72s\n",
      "  Validation accuracy improved to 0.6894. Saved model to ./models/best_lstm_model_sequences_sorted_1.pth\n",
      "Epoch 9/100 | Train Loss: 1.0365 | Train Acc: 0.6932 | Val Loss: 0.9489 | Val Acc: 0.7273 | Duration: 1.72s\n",
      "  Validation accuracy improved to 0.7273. Saved model to ./models/best_lstm_model_sequences_sorted_1.pth\n",
      "Epoch 10/100 | Train Loss: 0.9532 | Train Acc: 0.6989 | Val Loss: 0.8106 | Val Acc: 0.7879 | Duration: 1.80s\n",
      "  Validation accuracy improved to 0.7879. Saved model to ./models/best_lstm_model_sequences_sorted_1.pth\n",
      "Epoch 11/100 | Train Loss: 0.8395 | Train Acc: 0.7348 | Val Loss: 0.7073 | Val Acc: 0.8030 | Duration: 1.75s\n",
      "  Validation accuracy improved to 0.8030. Saved model to ./models/best_lstm_model_sequences_sorted_1.pth\n",
      "Epoch 12/100 | Train Loss: 0.7242 | Train Acc: 0.7898 | Val Loss: 0.6586 | Val Acc: 0.8030 | Duration: 1.73s\n",
      "Epoch 13/100 | Train Loss: 0.6274 | Train Acc: 0.8258 | Val Loss: 0.5793 | Val Acc: 0.8561 | Duration: 1.75s\n",
      "  Validation accuracy improved to 0.8561. Saved model to ./models/best_lstm_model_sequences_sorted_1.pth\n",
      "Epoch 14/100 | Train Loss: 0.5439 | Train Acc: 0.8409 | Val Loss: 0.4826 | Val Acc: 0.8939 | Duration: 1.73s\n",
      "  Validation accuracy improved to 0.8939. Saved model to ./models/best_lstm_model_sequences_sorted_1.pth\n",
      "Epoch 15/100 | Train Loss: 0.4695 | Train Acc: 0.8958 | Val Loss: 0.3888 | Val Acc: 0.9318 | Duration: 1.72s\n",
      "  Validation accuracy improved to 0.9318. Saved model to ./models/best_lstm_model_sequences_sorted_1.pth\n",
      "Epoch 16/100 | Train Loss: 0.4336 | Train Acc: 0.8807 | Val Loss: 0.4416 | Val Acc: 0.8788 | Duration: 1.75s\n",
      "Epoch 17/100 | Train Loss: 0.3872 | Train Acc: 0.9167 | Val Loss: 0.3767 | Val Acc: 0.9167 | Duration: 1.75s\n",
      "Epoch 18/100 | Train Loss: 0.3619 | Train Acc: 0.9205 | Val Loss: 0.3955 | Val Acc: 0.8788 | Duration: 1.75s\n",
      "Epoch 19/100 | Train Loss: 0.3468 | Train Acc: 0.9148 | Val Loss: 0.3626 | Val Acc: 0.8712 | Duration: 1.73s\n",
      "Epoch 20/100 | Train Loss: 0.2950 | Train Acc: 0.9451 | Val Loss: 0.3886 | Val Acc: 0.9015 | Duration: 1.73s\n",
      "Epoch 21/100 | Train Loss: 0.2857 | Train Acc: 0.9432 | Val Loss: 0.2979 | Val Acc: 0.9242 | Duration: 1.73s\n",
      "Epoch 22/100 | Train Loss: 0.2995 | Train Acc: 0.9318 | Val Loss: 0.4019 | Val Acc: 0.8561 | Duration: 1.78s\n",
      "Epoch 23/100 | Train Loss: 0.2926 | Train Acc: 0.9167 | Val Loss: 0.3598 | Val Acc: 0.8939 | Duration: 1.72s\n",
      "Epoch 24/100 | Train Loss: 0.2373 | Train Acc: 0.9545 | Val Loss: 0.2444 | Val Acc: 0.9545 | Duration: 1.75s\n",
      "  Validation accuracy improved to 0.9545. Saved model to ./models/best_lstm_model_sequences_sorted_1.pth\n",
      "Epoch 25/100 | Train Loss: 0.1889 | Train Acc: 0.9621 | Val Loss: 0.2679 | Val Acc: 0.9545 | Duration: 1.76s\n",
      "Epoch 26/100 | Train Loss: 0.2098 | Train Acc: 0.9451 | Val Loss: 0.2213 | Val Acc: 0.9242 | Duration: 1.78s\n",
      "Epoch 27/100 | Train Loss: 0.2065 | Train Acc: 0.9527 | Val Loss: 0.2779 | Val Acc: 0.8939 | Duration: 1.80s\n",
      "Epoch 28/100 | Train Loss: 0.1664 | Train Acc: 0.9735 | Val Loss: 0.1489 | Val Acc: 0.9697 | Duration: 1.79s\n",
      "  Validation accuracy improved to 0.9697. Saved model to ./models/best_lstm_model_sequences_sorted_1.pth\n",
      "Epoch 29/100 | Train Loss: 0.1411 | Train Acc: 0.9773 | Val Loss: 0.2228 | Val Acc: 0.9167 | Duration: 1.74s\n",
      "Epoch 30/100 | Train Loss: 0.1428 | Train Acc: 0.9678 | Val Loss: 0.1299 | Val Acc: 0.9697 | Duration: 1.79s\n",
      "Epoch 31/100 | Train Loss: 0.1379 | Train Acc: 0.9678 | Val Loss: 0.1356 | Val Acc: 0.9773 | Duration: 1.74s\n",
      "  Validation accuracy improved to 0.9773. Saved model to ./models/best_lstm_model_sequences_sorted_1.pth\n",
      "Epoch 32/100 | Train Loss: 0.2003 | Train Acc: 0.9527 | Val Loss: 0.1796 | Val Acc: 0.9621 | Duration: 1.73s\n",
      "Epoch 33/100 | Train Loss: 0.1756 | Train Acc: 0.9564 | Val Loss: 0.4510 | Val Acc: 0.8561 | Duration: 1.78s\n",
      "Epoch 34/100 | Train Loss: 0.3069 | Train Acc: 0.9205 | Val Loss: 0.2910 | Val Acc: 0.9091 | Duration: 1.74s\n",
      "Epoch 35/100 | Train Loss: 0.1710 | Train Acc: 0.9545 | Val Loss: 0.2116 | Val Acc: 0.9545 | Duration: 1.73s\n",
      "Epoch 36/100 | Train Loss: 0.1214 | Train Acc: 0.9830 | Val Loss: 0.2012 | Val Acc: 0.9470 | Duration: 1.76s\n",
      "Epoch 37/100 | Train Loss: 0.1051 | Train Acc: 0.9792 | Val Loss: 0.1213 | Val Acc: 0.9545 | Duration: 1.73s\n",
      "Epoch 38/100 | Train Loss: 0.0786 | Train Acc: 0.9886 | Val Loss: 0.0751 | Val Acc: 0.9773 | Duration: 1.74s\n",
      "Epoch 39/100 | Train Loss: 0.1582 | Train Acc: 0.9659 | Val Loss: 0.4317 | Val Acc: 0.8485 | Duration: 1.76s\n",
      "Epoch 40/100 | Train Loss: 0.1845 | Train Acc: 0.9413 | Val Loss: 0.2265 | Val Acc: 0.9091 | Duration: 1.74s\n",
      "Epoch 41/100 | Train Loss: 0.1366 | Train Acc: 0.9659 | Val Loss: 0.1415 | Val Acc: 0.9621 | Duration: 1.76s\n",
      "Epoch 42/100 | Train Loss: 0.1362 | Train Acc: 0.9697 | Val Loss: 0.0988 | Val Acc: 0.9773 | Duration: 1.76s\n",
      "Epoch 43/100 | Train Loss: 0.0818 | Train Acc: 0.9867 | Val Loss: 0.1143 | Val Acc: 0.9621 | Duration: 1.75s\n",
      "Epoch 44/100 | Train Loss: 0.0508 | Train Acc: 0.9962 | Val Loss: 0.1028 | Val Acc: 0.9545 | Duration: 1.75s\n",
      "Epoch 45/100 | Train Loss: 0.0678 | Train Acc: 0.9905 | Val Loss: 0.1237 | Val Acc: 0.9848 | Duration: 1.74s\n",
      "  Validation accuracy improved to 0.9848. Saved model to ./models/best_lstm_model_sequences_sorted_1.pth\n",
      "Epoch 46/100 | Train Loss: 0.1297 | Train Acc: 0.9583 | Val Loss: 0.1826 | Val Acc: 0.9470 | Duration: 1.76s\n",
      "Epoch 47/100 | Train Loss: 0.1613 | Train Acc: 0.9508 | Val Loss: 0.2566 | Val Acc: 0.9242 | Duration: 1.75s\n",
      "Epoch 48/100 | Train Loss: 0.2252 | Train Acc: 0.9375 | Val Loss: 0.1659 | Val Acc: 0.9242 | Duration: 1.75s\n",
      "Epoch 49/100 | Train Loss: 0.1525 | Train Acc: 0.9621 | Val Loss: 0.1790 | Val Acc: 0.9394 | Duration: 1.77s\n",
      "Epoch 50/100 | Train Loss: 0.1328 | Train Acc: 0.9716 | Val Loss: 0.1430 | Val Acc: 0.9470 | Duration: 1.73s\n",
      "Epoch 51/100 | Train Loss: 0.1670 | Train Acc: 0.9527 | Val Loss: 0.1644 | Val Acc: 0.9394 | Duration: 1.78s\n",
      "Epoch 52/100 | Train Loss: 0.1220 | Train Acc: 0.9659 | Val Loss: 0.2799 | Val Acc: 0.9015 | Duration: 1.76s\n",
      "Epoch 53/100 | Train Loss: 0.1885 | Train Acc: 0.9470 | Val Loss: 0.3755 | Val Acc: 0.8788 | Duration: 1.74s\n",
      "Epoch 54/100 | Train Loss: 0.1685 | Train Acc: 0.9527 | Val Loss: 0.2164 | Val Acc: 0.9167 | Duration: 1.73s\n",
      "Epoch 55/100 | Train Loss: 0.1253 | Train Acc: 0.9659 | Val Loss: 0.1252 | Val Acc: 0.9621 | Duration: 1.74s\n",
      "Epoch 56/100 | Train Loss: 0.1052 | Train Acc: 0.9678 | Val Loss: 0.1825 | Val Acc: 0.9394 | Duration: 1.76s\n",
      "Epoch 57/100 | Train Loss: 0.1000 | Train Acc: 0.9697 | Val Loss: 0.1394 | Val Acc: 0.9545 | Duration: 1.76s\n",
      "Epoch 58/100 | Train Loss: 0.2917 | Train Acc: 0.9242 | Val Loss: 0.2820 | Val Acc: 0.9167 | Duration: 1.76s\n",
      "Epoch 59/100 | Train Loss: 0.2310 | Train Acc: 0.9318 | Val Loss: 0.2300 | Val Acc: 0.9015 | Duration: 1.74s\n",
      "Epoch 60/100 | Train Loss: 0.1026 | Train Acc: 0.9773 | Val Loss: 0.1433 | Val Acc: 0.9545 | Duration: 1.73s\n",
      "  Early stopping triggered at epoch 60. Best Val Acc: 0.9848\n",
      "\n",
      "--- Training finished in 105.49 seconds ---\n",
      "\n",
      "Loading best model from ./models/best_lstm_model_sequences_sorted_1.pth for final evaluation on validation set...\n",
      "Final Validation Accuracy (Best Model): 0.9848\n",
      "Final Validation Loss (Best Model): 0.1237\n",
      "\n",
      "Saving training history plot to ./models/training_history_lstm.png\n",
      "Plot saved to ./models/training_history_lstm.png\n",
      "\n",
      "Saving label mapping to ./models/label_map_sequences.pickle\n",
      "Label mapping saved.\n",
      "\n",
      "--- Model training script finished ---\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time # <-- Added missing import\n",
    "\n",
    "# --- Configuration ---\n",
    "# Use the output file from the updated dataset script\n",
    "DATA_PICKLE_FILE = './train_data_set/asl_sequences_dataset_3D.pickle'\n",
    "MODEL_SAVE_DIR = './models'\n",
    "BEST_MODEL_PATH = os.path.join(MODEL_SAVE_DIR, 'best_lstm_model_sequences_3D.pth')\n",
    "LABEL_MAP_PATH = os.path.join(MODEL_SAVE_DIR, 'label_map_sequences.pickle')\n",
    "HISTORY_PLOT_PATH = os.path.join(MODEL_SAVE_DIR, 'training_history_lstm.png')\n",
    "\n",
    "# Ensure model save directory exists\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# --- Device Setup (Enable GPU if available) ---\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Apple Silicon GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# --- Load Data ---\n",
    "print(f\"Loading data from: {DATA_PICKLE_FILE}\")\n",
    "try:\n",
    "    with open(DATA_PICKLE_FILE, 'rb') as f:\n",
    "        data_dict = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file not found at {DATA_PICKLE_FILE}. Please run the dataset creation script first.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Extract data and labels (Data should be NumPy arrays from the new script)\n",
    "data = data_dict['data'] # Should be numpy array (N, seq_len, features)\n",
    "labels = data_dict['labels'] # Should be numpy array (N,)\n",
    "\n",
    "print(f\"Loaded {len(data)} samples.\")\n",
    "if len(data) == 0:\n",
    "    print(\"Error: No data loaded. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# --- Data Preparation ---\n",
    "# Data is already a NumPy array from the new dataset script\n",
    "data_array = data.astype(np.float32) # Ensure correct dtype\n",
    "labels_array = np.asarray(labels) # Ensure labels are numpy array\n",
    "\n",
    "print(f\"Data array shape: {data_array.shape}\") # Should be (num_samples, SEQUENCE_LENGTH, input_size) <-- Updated comment\n",
    "# Example: (num_samples, 10, 84) or (num_samples, 10, 126)\n",
    "\n",
    "# Convert labels to numeric\n",
    "unique_labels, counts = np.unique(labels_array, return_counts=True)\n",
    "label_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "numeric_labels = np.array([label_map[label] for label in labels_array])\n",
    "reverse_label_map = {i: label for label, i in label_map.items()}\n",
    "num_classes = len(unique_labels)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(\"Class distribution:\")\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"  - {label}: {count}\")\n",
    "# print(f\"Label map created: {label_map}\") # Optional: print if needed\n",
    "\n",
    "# Split data (Train/Validation)\n",
    "# Using 'test' set as validation during training for simplicity.\n",
    "# For rigorous results, consider a separate test set.\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    data_array, numeric_labels, test_size=0.2, shuffle=True, stratify=numeric_labels, random_state=42\n",
    ")\n",
    "print(f\"Train samples: {len(x_train)}, Validation samples: {len(x_val)}\")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "x_val_tensor = torch.tensor(x_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "batch_size = 32 # Adjust as needed based on GPU memory\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor) # Use validation set here\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True) # Renamed to val_loader\n",
    "\n",
    "# --- Define LSTM Model ---\n",
    "class HandGestureLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_prob=0.5):\n",
    "        super(HandGestureLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # batch_first=True means input tensor shape is (batch, seq_len, features)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
    "                            batch_first=True, dropout=dropout_prob if num_layers > 1 else 0,\n",
    "                            bidirectional=False) # Can experiment with bidirectional=True\n",
    "        # If bidirectional=True, self.fc input size needs to be hidden_size * 2\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes) # Adjust if bidirectional\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state and cell state with zeros\n",
    "        # Shape: (num_layers * num_directions, batch_size, hidden_size)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device) # Adjust num_layers * 2 if bidirectional\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device) # Adjust num_layers * 2 if bidirectional\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        # out contains outputs for every time step\n",
    "        # hn is the hidden state for the last time step\n",
    "        # cn is the cell state for the last time step\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        # out: (batch_size, seq_length, hidden_size * num_directions)\n",
    "        # We use the output of the last time step: out[:, -1, :]\n",
    "        # Shape: (batch_size, hidden_size * num_directions)\n",
    "        last_time_step_out = out[:, -1, :]\n",
    "\n",
    "        # Apply dropout and final linear layer\n",
    "        out = self.dropout(last_time_step_out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# --- Model Initialization ---\n",
    "input_size = data_array.shape[2] # Dynamically determined (e.g., 84 or 126)\n",
    "hidden_size = 128 # Can be tuned\n",
    "num_layers = 2    # Can be tuned (e.g., 1 or 2 layers)\n",
    "dropout_prob = 0.5 # Can be tuned\n",
    "\n",
    "model = HandGestureLSTM(input_size, hidden_size, num_layers, num_classes, dropout_prob).to(device)\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)\n",
    "print(f\"Input size: {input_size}\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Learning rate can be tuned\n",
    "# Consider using a learning rate scheduler\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "\n",
    "# --- Training and Evaluation Functions ---\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train() # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True) # Use non_blocking with pin_memory\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        # Optional: Gradient clipping\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += targets.size(0)\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate_epoch(model, val_loader, criterion, device): # Changed loader name\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.inference_mode(): # Use inference_mode for efficiency\n",
    "        for inputs, targets in val_loader: # Changed loader name\n",
    "            inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += targets.size(0)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# --- Training Loop ---\n",
    "epochs = 100 # Adjust as needed\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "best_val_acc = 0.0\n",
    "patience = 15 # Number of epochs to wait for improvement before stopping\n",
    "counter = 0\n",
    "\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate_epoch(model, val_loader, criterion, device) # Use val_loader\n",
    "\n",
    "    epoch_duration = time.time() - epoch_start_time\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs} | '\n",
    "          f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | '\n",
    "          f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | '\n",
    "          f'Duration: {epoch_duration:.2f}s')\n",
    "\n",
    "    # Optional: Adjust learning rate with scheduler\n",
    "    # scheduler.step(val_loss)\n",
    "\n",
    "    # Early stopping and saving best model based on validation accuracy\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        counter = 0\n",
    "        # Save best model state dictionary\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        print(f'  Validation accuracy improved to {best_val_acc:.4f}. Saved model to {BEST_MODEL_PATH}')\n",
    "    else:\n",
    "        counter += 1\n",
    "        # print(f'  Validation accuracy did not improve. Counter: {counter}/{patience}') # Optional: less verbose\n",
    "        if counter >= patience:\n",
    "            print(f'  Early stopping triggered at epoch {epoch+1}. Best Val Acc: {best_val_acc:.4f}')\n",
    "            break\n",
    "\n",
    "training_duration = time.time() - start_time\n",
    "print(f\"\\n--- Training finished in {training_duration:.2f} seconds ---\")\n",
    "\n",
    "# --- Final Evaluation on Validation Set (using the best model) ---\n",
    "print(f\"\\nLoading best model from {BEST_MODEL_PATH} for final evaluation on validation set...\")\n",
    "try:\n",
    "    # Load the best performing model state\n",
    "    # Create a new instance or load into the existing model\n",
    "    # Ensure the model definition matches the saved state_dict\n",
    "    model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=device))\n",
    "    model.to(device) # Ensure model is on the correct device\n",
    "\n",
    "    final_val_loss, final_val_acc = evaluate_epoch(model, val_loader, criterion, device)\n",
    "    print(f'Final Validation Accuracy (Best Model): {final_val_acc:.4f}')\n",
    "    print(f'Final Validation Loss (Best Model): {final_val_loss:.4f}')\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Best model file not found at {BEST_MODEL_PATH}. Cannot perform final evaluation.\")\n",
    "except Exception as e:\n",
    "     print(f\"Error loading best model or evaluating: {e}\")\n",
    "\n",
    "\n",
    "# --- Plot Training History ---\n",
    "print(f\"\\nSaving training history plot to {HISTORY_PLOT_PATH}\")\n",
    "try:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    # Only plot up to the point where training stopped\n",
    "    epochs_ran = len(train_accs)\n",
    "    plt.plot(range(1, epochs_ran + 1), train_accs, label='Train Accuracy')\n",
    "    plt.plot(range(1, epochs_ran + 1), val_accs, label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epochs_ran + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, epochs_ran + 1), val_losses, label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(HISTORY_PLOT_PATH) # Save the plot\n",
    "    print(f\"Plot saved to {HISTORY_PLOT_PATH}\")\n",
    "    # plt.show() # Uncomment to display plot immediately if running interactively\n",
    "    plt.close() # Close the plot figure to free memory\n",
    "except Exception as e:\n",
    "    print(f\"Error generating or saving plot: {e}\")\n",
    "\n",
    "\n",
    "# --- Save Label Mapping ---\n",
    "print(f\"\\nSaving label mapping to {LABEL_MAP_PATH}\")\n",
    "try:\n",
    "    with open(LABEL_MAP_PATH, 'wb') as f:\n",
    "        pickle.dump({'label_map': label_map, 'reverse_label_map': reverse_label_map}, f)\n",
    "    print(\"Label mapping saved.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving label map: {e}\")\n",
    "\n",
    "print(\"\\n--- Model training script finished ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1438773f",
   "metadata": {},
   "source": [
    "<h2> 4. Live Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0879b764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Apple Silicon GPU)\n",
      "Loading label mapping from: ./models_padded/label_map_padded.pickle\n",
      "Loaded 33 classes.\n",
      "Loading model from: ./models_padded/best_lstm_model_padded.pth\n",
      "Model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746336262.732085 27857068 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Pro\n",
      "W0000 00:00:1746336262.742397 28462300 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746336262.751878 28462300 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Live Recognition...\n",
      "Press 'Q' or 'Esc' to exit.\n",
      "\n",
      "Exiting...\n",
      "Resources released.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import deque\n",
    "import time # For FPS calculation\n",
    "import os # Added for path joining\n",
    "\n",
    "# --- Configuration ---\n",
    "MODEL_SAVE_DIR = './models'\n",
    "BEST_MODEL_PATH = os.path.join(MODEL_SAVE_DIR, 'best_lstm_model_sequences_sorted.pth')\n",
    "LABEL_MAP_PATH = os.path.join(MODEL_SAVE_DIR, 'label_map_sequences.pickle')\n",
    "\n",
    "SEQUENCE_LENGTH = 10          # Must match the training sequence length\n",
    "NUM_LANDMARKS = 21\n",
    "FEATURES_PER_LANDMARK = 2\n",
    "FEATURES_PER_HAND = NUM_LANDMARKS * FEATURES_PER_LANDMARK # 42\n",
    "TARGET_FEATURES_PER_FRAME = FEATURES_PER_HAND * 2         # 84 (for two hands, padded)\n",
    "PREDICTION_THRESHOLD = 0.6   # Minimum confidence to display prediction\n",
    "\n",
    "# --- Define LSTM Model Class (Must match training architecture) ---\n",
    "class HandGestureLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_prob=0.5):\n",
    "        super(HandGestureLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
    "                            batch_first=True, dropout=dropout_prob if num_layers > 1 else 0)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        # Get output of the last time step and apply dropout\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        # Pass through final fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# --- Device Setup ---\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Apple Silicon GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# --- Load Label Mapping ---\n",
    "print(f\"Loading label mapping from: {LABEL_MAP_PATH}\")\n",
    "try:\n",
    "    with open(LABEL_MAP_PATH, 'rb') as f:\n",
    "        label_info = pickle.load(f)\n",
    "        label_map = label_info['label_map']\n",
    "        reverse_label_map = label_info['reverse_label_map']\n",
    "        num_classes = len(label_map)\n",
    "        print(f\"Loaded {num_classes} classes.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Label map file not found at {LABEL_MAP_PATH}.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading label map file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Load Model ---\n",
    "print(f\"Loading model from: {BEST_MODEL_PATH}\")\n",
    "# Determine model parameters (these should ideally be saved with the model or known)\n",
    "input_size = TARGET_FEATURES_PER_FRAME # 84\n",
    "hidden_size = 128 # Must match the hidden_size used during training\n",
    "num_layers = 2    # Must match the num_layers used during training\n",
    "dropout_prob = 0.5 # Must match dropout used during training\n",
    "\n",
    "model = HandGestureLSTM(input_size, hidden_size, num_layers, num_classes, dropout_prob)\n",
    "try:\n",
    "    # Load the state dictionary onto the specified device\n",
    "    model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=device))\n",
    "    model.to(device) # Ensure model is on the correct device\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    print(\"Model loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model file not found at {BEST_MODEL_PATH}.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model state dictionary: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- MediaPipe Initialization ---\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2, # Detect up to two hands\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# --- Helper Function for Normalization ---\n",
    "def normalize_landmarks(landmarks, image_shape):\n",
    "    \"\"\"Normalizes landmarks relative to the hand's bounding box.\"\"\"\n",
    "    if not landmarks: return None\n",
    "    # Get pixel coordinates first to calculate bounding box correctly\n",
    "    x_coords_px = [lm.x * image_shape[1] for lm in landmarks.landmark]\n",
    "    y_coords_px = [lm.y * image_shape[0] for lm in landmarks.landmark]\n",
    "    if not x_coords_px or not y_coords_px: return None\n",
    "\n",
    "    x_min_px, x_max_px = min(x_coords_px), max(x_coords_px)\n",
    "    y_min_px, y_max_px = min(y_coords_px), max(y_coords_px)\n",
    "\n",
    "    # Calculate width and height for normalization denominator\n",
    "    box_width = x_max_px - x_min_px\n",
    "    box_height = y_max_px - y_min_px\n",
    "\n",
    "    # Avoid division by zero for degenerate bounding boxes\n",
    "    if box_width == 0 or box_height == 0: return None\n",
    "\n",
    "    normalized_features = []\n",
    "    for lm in landmarks.landmark:\n",
    "        # Normalize relative to the bounding box dimensions\n",
    "        norm_x = (lm.x * image_shape[1] - x_min_px) / box_width\n",
    "        norm_y = (lm.y * image_shape[0] - y_min_px) / box_height\n",
    "        normalized_features.extend([norm_x, norm_y])\n",
    "\n",
    "    # Ensure correct feature count\n",
    "    return normalized_features if len(normalized_features) == FEATURES_PER_HAND else None\n",
    "\n",
    "# --- Live Test Initialization ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "sequence_buffer = deque(maxlen=SEQUENCE_LENGTH) # Buffer to hold the last N frames' features\n",
    "current_prediction = \"\"\n",
    "current_confidence = 0.0\n",
    "\n",
    "# For FPS calculation\n",
    "frame_count = 0\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"\\nStarting Live Recognition...\")\n",
    "print(\"Press 'Q' or 'Esc' to exit.\")\n",
    "\n",
    "# Define window name\n",
    "WINDOW_NAME = 'ASL Live Recognition (LSTM)'\n",
    "\n",
    "while True:\n",
    "    # --- Frame Capture and FPS ---\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture frame.\")\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    elapsed_time = time.time() - start_time\n",
    "    fps = frame_count / elapsed_time if elapsed_time > 0 else 0\n",
    "\n",
    "    H, W, _ = frame.shape\n",
    "    display_frame = frame.copy() # Work on a copy for drawing\n",
    "\n",
    "    # --- MediaPipe Processing ---\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image_rgb.flags.writeable = False # Optimize\n",
    "    results = hands.process(image_rgb)\n",
    "    image_rgb.flags.writeable = True\n",
    "\n",
    "    # --- Landmark Extraction and Feature Creation ---\n",
    "    frame_features = np.zeros(TARGET_FEATURES_PER_FRAME, dtype=np.float32) # Start with zeros (padding)\n",
    "    detected_hands_landmarks = [] # Store raw landmarks for drawing bounding boxes later\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        normalized_hands_features = []\n",
    "\n",
    "        for hand_idx, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "            if hand_idx >= 2: break # Process max 2 hands\n",
    "\n",
    "            # Draw landmarks on the display frame\n",
    "            mp_drawing.draw_landmarks(\n",
    "                display_frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "            # Normalize features for this hand\n",
    "            norm_features = normalize_landmarks(hand_landmarks, frame.shape)\n",
    "            if norm_features:\n",
    "                normalized_hands_features.append(norm_features)\n",
    "                # Store raw landmarks for bounding box calculation later\n",
    "                detected_hands_landmarks.append(hand_landmarks) # Store landmarks object\n",
    "\n",
    "        # Assign features (handle 1 vs 2 hands)\n",
    "        if len(normalized_hands_features) == 1:\n",
    "            frame_features[:FEATURES_PER_HAND] = normalized_hands_features[0]\n",
    "        elif len(normalized_hands_features) == 2:\n",
    "            # Simple assignment: first detected -> first slot, second -> second slot\n",
    "            frame_features[:FEATURES_PER_HAND] = normalized_hands_features[0]\n",
    "            frame_features[FEATURES_PER_HAND:] = normalized_hands_features[1]\n",
    "\n",
    "    # --- Sequence Management and Prediction ---\n",
    "    sequence_buffer.append(frame_features)\n",
    "\n",
    "    # Only predict if the buffer is full\n",
    "    if len(sequence_buffer) == SEQUENCE_LENGTH:\n",
    "        try:\n",
    "            # Prepare input tensor for LSTM: (1, seq_len, features)\n",
    "            input_sequence = np.array(list(sequence_buffer), dtype=np.float32)\n",
    "            input_tensor = torch.FloatTensor(input_sequence).unsqueeze(0).to(device) # Add batch dimension\n",
    "\n",
    "            # Make prediction\n",
    "            with torch.inference_mode(): # Use inference mode\n",
    "                outputs = model(input_tensor)\n",
    "                probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                confidence, predicted_idx = torch.max(probabilities, 1)\n",
    "\n",
    "                pred_idx = predicted_idx.item()\n",
    "                conf_val = confidence.item()\n",
    "\n",
    "                # Update current prediction if confidence is high enough\n",
    "                if conf_val >= PREDICTION_THRESHOLD:\n",
    "                    # Check if the prediction index is valid\n",
    "                    if pred_idx in reverse_label_map:\n",
    "                        current_prediction = reverse_label_map[pred_idx]\n",
    "                        current_confidence = conf_val\n",
    "                    else:\n",
    "                        print(f\"Warning: Predicted index {pred_idx} not in reverse_label_map.\")\n",
    "                        current_prediction = \"Unknown\"\n",
    "                        current_confidence = conf_val # Still show confidence\n",
    "                else:\n",
    "                    # Confidence below threshold, clear prediction\n",
    "                    current_prediction = \"\"\n",
    "                    current_confidence = 0.0\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Prediction error: {e}\")\n",
    "            current_prediction = \"Error\"\n",
    "            current_confidence = 0.0\n",
    "\n",
    "    # --- Drawing Bounding Boxes and Predictions ---\n",
    "    # Draw bounding boxes for detected hands\n",
    "    for hand_landmarks in detected_hands_landmarks:\n",
    "         # Calculate bounding box from the landmarks object\n",
    "         x_coords = [lm.x for lm in hand_landmarks.landmark]\n",
    "         y_coords = [lm.y for lm in hand_landmarks.landmark]\n",
    "         if x_coords and y_coords:\n",
    "             x_min, x_max = min(x_coords), max(x_coords)\n",
    "             y_min, y_max = min(y_coords), max(y_coords)\n",
    "             # Convert relative coords to pixel coords\n",
    "             x1 = max(0, int(x_min * W) - 10)\n",
    "             y1 = max(0, int(y_min * H) - 10)\n",
    "             x2 = min(W, int(x_max * W) + 10)\n",
    "             y2 = min(H, int(y_max * H) + 10)\n",
    "             cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 2) # Green box\n",
    "\n",
    "    # Display FPS\n",
    "    cv2.putText(display_frame, f\"FPS: {fps:.1f}\", (W - 100, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display Prediction Status\n",
    "    pred_text = f\"Prediction: {current_prediction} ({current_confidence:.2f})\" if current_prediction else \"Prediction: ...\"\n",
    "    cv2.putText(display_frame, pred_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display Buffer Status\n",
    "    buffer_status = f\"Buffer: {len(sequence_buffer)}/{SEQUENCE_LENGTH}\"\n",
    "    cv2.putText(display_frame, buffer_status, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # --- Display Frame ---\n",
    "    cv2.imshow(WINDOW_NAME, display_frame)\n",
    "\n",
    "    # --- Exit Condition ---\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q') or key == 27: # 27 is Escape key\n",
    "        break\n",
    "\n",
    "# --- Cleanup ---\n",
    "print(\"\\nExiting...\")\n",
    "cap.release()\n",
    "# Explicitly destroy the named window\n",
    "try:\n",
    "    cv2.destroyWindow(WINDOW_NAME)\n",
    "except cv2.error:\n",
    "    # Window might have been closed manually or never opened properly\n",
    "    pass\n",
    "# Close all other potential OpenCV windows\n",
    "cv2.destroyAllWindows()\n",
    "# Ensure any remaining GUI events are processed (optional, can help on some systems)\n",
    "for i in range(5):\n",
    "    cv2.waitKey(1)\n",
    "# Release MediaPipe hands resources\n",
    "hands.close()\n",
    "print(\"Resources released.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26b4f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Apple Silicon GPU)\n",
      "Loading label mapping from: ./models/label_map_sequences.pickle\n",
      "Loaded 33 classes.\n",
      "Loading model from: ./models/best_lstm_model_sequences.pth\n",
      "Model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746308807.141943 27857068 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Pro\n",
      "W0000 00:00:1746308807.146317 27862883 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746308807.150444 27862883 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Live Recognition ---\n",
      "------------------------------------\n",
      "Added: Hello | Sentence: Hello\n",
      "Added: [SPACE]\n",
      "Added: My | Sentence: Hello My\n",
      "Added: [SPACE]\n",
      "Added: Name | Sentence: Hello My Name\n",
      "Added: [SPACE]\n",
      "Added: N | Sentence: Hello My Name N\n",
      "Added: A | Sentence: Hello My Name NA\n",
      "Added: M | Sentence: Hello My Name NAM\n",
      "Added: [SPACE]\n",
      "\n",
      "Sending to API: 'Hello My Name NAM'\n",
      "DUMMY API: Analyzing 'Hello My Name NAM'\n",
      "API Response: Meaning: NAM Name My Hello\n",
      "\n",
      "Exiting...\n",
      "Resources released.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
